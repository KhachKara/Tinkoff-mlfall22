{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ml_s10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMfis9rtZ2Ze51+SeHT9kO8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Ансамбли"],"metadata":{"id":"u_RpqYQEb6I2"}},{"cell_type":"markdown","source":["В рамках этого семинара мы с вами попробуем различные алгоритмы ансамблирования для решения задачи классификации на [данных о транзакциях](https://www.kaggle.com/datasets/miznaaroob/fraudulent-transactions-data). Цель - определить, является ли транзакция мошеннической."],"metadata":{"id":"fO6xDg72cZKk"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"QiFbZL6gcY0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown 1X11Qb_9opv2D3_1SjUOA5MZ7Sx84pT8o -O fraud.csv"],"metadata":{"id":"wRg1iRJMBMAJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('fraud.csv')\n","\n","df.head()"],"metadata":{"id":"EE01aF7RGOMW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isna().any()"],"metadata":{"id":"B4wfVQWXh_i8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isFraud.value_counts(normalize=True)"],"metadata":{"id":"MioNPCH5KAEU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X, y = df.drop(\n","    columns=['nameOrig', 'nameDest', 'isFlaggedFraud', 'isFraud']\n",").rename(\n","    columns={'oldbalanceOrg': 'oldbalanceOrig'}\n","), df.isFraud"],"metadata":{"id":"MoHZoZFfJH5F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.65, random_state=42)\n","len(X_train), len(X_test)"],"metadata":{"id":"iim1GLl1Gae-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","\n","\n","encoder = OneHotEncoder(handle_unknown='ignore')\n","type_encoded_train = encoder.fit_transform(X_train['type'].to_numpy().reshape(-1, 1)).todense()\n","type_encoded_test = encoder.transform(X_test['type'].to_numpy().reshape(-1, 1)).todense()\n","feature_names = encoder.get_feature_names_out()"],"metadata":{"id":"Z-UlWKD5q-WP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type_encoded_train_df = pd.DataFrame(data=type_encoded_train, columns=feature_names)\n","type_encoded_test_df = pd.DataFrame(data=type_encoded_test, columns=feature_names)\n","\n","type_encoded_train_df.index = X_train.index\n","type_encoded_test_df.index = X_test.index\n","\n","X_train = pd.concat([X_train.drop(columns=['type']), type_encoded_train_df], axis=1)\n","X_test = pd.concat([X_test.drop(columns=['type']), type_encoded_test_df], axis=1)"],"metadata":{"id":"MVm2nVKC0fFQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Baseline"],"metadata":{"id":"ioD9iWqKi8Px"}},{"cell_type":"markdown","source":["Решим задачу базовыми алгоритмами:\n","\n","1. Предсказанием самого популярного класса\n","2. Логистической регрессией\n","3. Решающим деревом"],"metadata":{"id":"jiEO5zG9jAQ3"}},{"cell_type":"markdown","source":["### Dummy-модель"],"metadata":{"id":"rZ9BVhHtpXoB"}},{"cell_type":"code","source":["from sklearn.dummy import DummyClassifier\n","\n","\n","dummy = DummyClassifier()\n","dummy.fit(X_train, y_train)\n","y_pred = dummy.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"s3DlBI3TpdBZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Видим вполне предсказуемые результаты - доминантный класс предсказан хорошо, accuracy выглядит прилично, но метрики по минорному классу нулевые. Отсюда низкие усреднённые precision, recall и F1."],"metadata":{"id":"qLp-kewvqDoZ"}},{"cell_type":"markdown","source":["### Регрессия"],"metadata":{"id":"Hvf8I2IRqcFY"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","\n","log_reg = LogisticRegression(random_state=42)\n","log_reg.fit(X_train, y_train)\n","y_pred = log_reg.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"Q9R7yvh1qgZh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Регрессия работает на этих данных, у нас неплохо подрос F1. Проверим, как справится дерево со стандартными параметрами."],"metadata":{"id":"cmZn8lAQ3AYW"}},{"cell_type":"markdown","source":["### Дерево"],"metadata":{"id":"hBxbmlmk3LHu"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","\n","\n","tree = DecisionTreeClassifier(random_state=42)\n","tree.fit(X_train, y_train)\n","y_pred = tree.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"-HcJUhJR3Md1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Дерево справилось отлично. Теперь будем сравнивать его эффективность с алгоритмами ансамблирования."],"metadata":{"id":"of7jN2MN3a4W"}},{"cell_type":"markdown","source":["## Случайный лес"],"metadata":{"id":"3HeNxsiu3zje"}},{"cell_type":"markdown","source":["Построим для дерева график изменения F1-score в зависимости от глубины, т.к. хотим убедиться, что при той же глубине деревьев лес будет более устойчивым."],"metadata":{"id":"iCm7q_c841Zd"}},{"cell_type":"code","source":["# возьмем код с предыдущего семинара\n","\n","import seaborn as sns\n","from tqdm import tqdm\n","\n","\n","def plot_fitting_curve(\n","    model_ctor, parameter: str, values: list, score, X_train, X_test, y_train, y_test\n","):\n","    train_curve = []\n","    test_curve = []\n","    for value in tqdm(values):\n","        model = model_ctor(**{parameter: value, 'random_state': 42})  # теперь создаем произвольную модель, конструктор которой нам был передан снаружи\n","        model.fit(X_train, y_train)\n","        y_pred_train, y_pred_test = model.predict(X_train), model.predict(X_test)\n","        train_curve.append(score(y_train, y_pred_train, average='macro'))\n","        test_curve.append(score(y_test, y_pred_test, average='macro'))\n","    sns.lineplot(x=values, y=train_curve)\n","    sns.lineplot(x=values, y=test_curve)"],"metadata":{"id":"7bCYdxpJ4zv1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","\n","plot_fitting_curve(DecisionTreeClassifier, 'max_depth', np.arange(1, 20), f1_score, X_train, X_test, y_train, y_test)"],"metadata":{"id":"6IPfqLBb5fPG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Видим, что на отметке 10 дерево уже становится склонным к переобучению. "],"metadata":{"id":"KI6A-BZR5xQ_"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","plot_fitting_curve(RandomForestClassifier, 'max_depth', np.arange(6, 16, 2), f1_score, X_train, X_test, y_train, y_test)"],"metadata":{"id":"AWrdYaQ54Rw_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Наша гипотеза подтвердилась, бэггинг на деревьях с глубиной дерева 12 ещё не переобучается. Видим, что лес является более устойчивой моделью."],"metadata":{"id":"H1LGQFBH-eR5"}},{"cell_type":"code","source":["tree = DecisionTreeClassifier(max_depth=10, random_state=42)  # обучим \"хорошее\" дерево\n","tree.fit(X_train, y_train)\n","y_pred = tree.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"qA3ArpdqAJHv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tree = DecisionTreeClassifier(max_depth=20, random_state=42)  # обучим дерево, склонное к переобучению\n","tree.fit(X_train, y_train)\n","y_pred = tree.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"MiIrHRVt_JoI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["forest = RandomForestClassifier(max_depth=20, random_state=42, n_jobs=-1)  # обучим аналогичный бэггинг\n","forest.fit(X_train, y_train)\n","y_pred = forest.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"fImUIWvJ_KMA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Видим, что даже при большей глубине бэггинг является более устойчивым и показывает лучший результат."],"metadata":{"id":"zouljsB0AFzP"}},{"cell_type":"markdown","source":["## Стандартный бустинг"],"metadata":{"id":"gXhvvQJaoA1o"}},{"cell_type":"markdown","source":["Посмотрим, как работает классификатор на бустинге. Важно: здесь мы будем всегда фиксировать значение параметра `random_state`, потому что сам по себе бустинг довольно неустойчив.\n","\n","+ параметр verbose"],"metadata":{"id":"1XsGtmcdI4wg"}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","\n","vanilla_boosting = GradientBoostingClassifier(random_state=42)  # возьмем стандартные параметры\n","vanilla_boosting.fit(X_train, y_train)\n","y_pred = vanilla_boosting.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"yerc8weJI4VI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Модель обучалась долго, но результат удивительно слабый. Что могло пойти не так?\n","\n","Для начала попробуем ускорить обучение нашей модели. Для этого есть замечательный параметр `n_iter_no_change`, по сути выполняющий раннюю остановку обучения. Если добавление новых моделей не улучшает качество общей модели в течение нескольких итераций подряд, то мы завершаем обучение."],"metadata":{"id":"AmivqB4tJGBJ"}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","\n","vanilla_boosting = GradientBoostingClassifier(n_iter_no_change=5, random_state=42)\n","vanilla_boosting.fit(X_train, y_train)\n","y_pred = vanilla_boosting.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"tlTi8ciHJ01f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Зафиксируем значение `n_iter_no_change = 5` и посмотрим, как ещё мы можем улучшить качество модели или ускорить обучение."],"metadata":{"id":"riEtsc1MMCXH"}},{"cell_type":"code","source":["# параметр subsample регулирует то, на какой части исходного датасета учится очередная модель\n","\n","vanilla_boosting = GradientBoostingClassifier(subsample=0.8, n_iter_no_change=5, random_state=42)\n","vanilla_boosting.fit(X_train, y_train)\n","y_pred = vanilla_boosting.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"APc_LEtyBR6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# параметр learning_rate регулирует долю от предсказания очередной модели, которую мы прибавляем к суммарному ответу\n","\n","vanilla_boosting = GradientBoostingClassifier(learning_rate=5e-2, n_iter_no_change=5, random_state=42)\n","vanilla_boosting.fit(X_train, y_train)\n","y_pred = vanilla_boosting.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"SoGRL-W4OnET"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## XGBoost"],"metadata":{"id":"tdtMNAUxoFjg"}},{"cell_type":"markdown","source":["XGBoost - библиотека с исходным кодом, в которой реализованы основные алгоритмы бустинга. Основная особенность XGBoost - параметры для регуляризации получившихся моделей:\n","\n","* `booster`\n","* `reg_alpha`\n","* `reg_lambda`\n","\n"],"metadata":{"id":"LMlwuNVA2Ung"}},{"cell_type":"code","source":["from xgboost import XGBClassifier"],"metadata":{"id":"Kcw1sLsBzFDg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xgboosting = XGBClassifier(random_state=42)\n","xgboosting.fit(X_train, y_train)\n","y_pred = xgboosting.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"L4kVsu8AzLj6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Рассмотрим подробнее параметр `booster`. Он может принимать следующие значения:\n","\n","1. `gbtree` - обычный бустинг на деревьях\n","2. `gblinear` - бустинг на регрессиях\n","3. `dart` - бустинг на деревьях с дропаутом\n","\n","dropout - удаление из модели части параметров для уменьшения емкости модели (одна из техник регуляризации)"],"metadata":{"id":"AFo0N0NU2aNl"}},{"cell_type":"code","source":["xgboosting = XGBClassifier(booster='dart', random_state=42)\n","xgboosting.fit(X_train, y_train)\n","y_pred = xgboosting.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"FaIAZvi611-T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LightGBM"],"metadata":{"id":"OZyrADNqoI36"}},{"cell_type":"markdown","source":["LightGBM - библиотека с бустингами от Microsoft, идеологическое продолжение XGBoost. Основная особенность библиотеки - скорость. Модели содержат очень много настроек и кода для ускорения обучения и инференса."],"metadata":{"id":"SmmZPDqI5BB7"}},{"cell_type":"code","source":["from lightgbm import LGBMClassifier"],"metadata":{"id":"pS6wfmslzwp5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lgboosting = LGBMClassifier(learning_rate=1e-2, random_state=42)\n","lgboosting.fit(X_train, y_train)\n","y_pred = lgboosting.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"FxEXVyqq4zZA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CatBoost"],"metadata":{"id":"zcBJsNrtoKmy"}},{"cell_type":"markdown","source":["CatBoost - библиотека от Яндекса. Почти все делает из коробки, не требует перебора гиперпараметров. Всё, что нужно - подготовить достаточно чистые данные. За счет внутреннего подбора настроек работает дольше, чем XGBoost и LGBM."],"metadata":{"id":"uPKKaZvTElOk"}},{"cell_type":"code","source":["!pip install catboost"],"metadata":{"id":"fiGrP9WE0Ssk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from catboost import CatBoostClassifier"],"metadata":{"id":"J6TOLb_wPKVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["catboosting = CatBoostClassifier(metric_period=50, random_state=42)\n","catboosting.fit(X_train, y_train)\n","y_pred = catboosting.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, digits=4))"],"metadata":{"id":"7Yz9tTRJ0kpR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Sr8j3YIn4Cj1"},"execution_count":null,"outputs":[]}]}