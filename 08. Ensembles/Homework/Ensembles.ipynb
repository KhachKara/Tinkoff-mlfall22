{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jSesEiLRkV2M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVTZmFccmyHP"
      },
      "source": [
        "# Домашняя работа: ансамбли"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE36FyB9m4Gp"
      },
      "source": [
        "Эта домашняя работа является идейным продолжением предыдущей. В данной работе вам будет необходимо поэкспериментировать с различными методами ансамблирования и проверить, какие из них работают лучше. Пайплайн предобработки данных можно взять полностью из предыдущей работы.\n",
        "\n",
        "Требования к домашней работе:\n",
        "- Во всех графиках (если вы их строите) должны быть подписи через title, legend, etc.\n",
        "- Во время обучения моделей проверяйте, что у вас не текут данные. Обычно это позитивно влияет на качество модели на тесте, но негативно влияет на оценку 🌚\n",
        "- Если вы сдаете работу в Google Colaboratory, убедитесь, что ваша тетрадка доступна по ссылке. Если в итоге по каким-то причинам тетрадка не будет открываться у преподавателя, задание не будет засчитано\n",
        "- Использование мемов допускается. Если задания дались тяжело, можно дополнительно приложить какой-нибудь постироничный мем про ваши страдания во время выполнения данной домашней работы. За мемы с использованием нецензурной лексики баллы будут снижены."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u-DyeiInWN2"
      },
      "source": [
        "# Загрузка и подготовка данных (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfY_eyP7nc3P"
      },
      "source": [
        "В этой секции предлагается прогнать предобработку данных из прошлой тетрадки заново и сохранить получившийся датасет в формате csv.\n",
        "\n",
        "Если вы **не хотите заморачиваться**, то просто скопируйте код с предобработкой ниже.\n",
        "\n",
        "В противном случае в старой тетрадке:\n",
        "1. Отдельно выполните предобработку (`fit_transform`) тренировочной части данных\n",
        "2. Добавьте колонку `split` к датафрейму с обучающей выборкой, в этой колонке проставьте значение `train` для всех объектов\n",
        "3. Затем примените **только** предобработку (`transform`) к тестовой части данных\n",
        "4. Добавьте колонку `split` к тестовой выборке, в этой колонке проставьте значение `test` для всех объектов\n",
        "5. Объедините два датафрейма в один при помощи функции `pd.concat`\n",
        "6. Сохраните получившийся датафрейм при помощи функции `to_csv`, не забудьте передать аргумент `index=False`\n",
        "\n",
        "Получившийся файл сохраните отдельно и используйте в этой домашней работе. Для разбиения датасета на обучающую и тестовую части вместо функции `train_test_split` можете применять колонку `split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "h7kSBxwxqBE9"
      },
      "outputs": [],
      "source": [
        "path = \"C:/Users/Дмитрий/Desktop/hw_10/ml-fall22/10. Ensembles/prepaired_data.csv\"\n",
        "prepaired_data = pd.read_csv(path)\n",
        "X_train, X_test = prepaired_data.query('split==\"train\"'), prepaired_data.query('split==\"test\"')\n",
        "y_train, y_test = prepaired_data.query('split==\"train\"').target, prepaired_data.query('split==\"test\"').target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")\n",
        "\n",
        "trans = ColumnTransformer(\n",
        "    [('num', StandardScaler(with_mean=False), [1,2,3,4]),\n",
        "     ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), [0,5,6,7,8,9])])\n",
        "\n",
        "X_train= trans.fit_transform(X_train)\n",
        "X_test = trans.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXUtaMSv5oGF"
      },
      "source": [
        "Важно: во всех разделах ниже задачу регрессии важно оценивать не только при помощи `MSE`, но и при помощи `r2_score`. Если вы хотите перебрать какой-либо гиперпараметр, не забывайте оценивать то, насколько сильно переобучается модель и как меняется каждый из параметров в процессе обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K3HJ_AqLg9i"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO5VjK7kp_si"
      },
      "source": [
        "# Стекинг (максимум 3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDbjOEre6Xst"
      },
      "source": [
        "Решите задачу, используя разные комбинации базовых моделей. В качестве базовой модели обязательно попробуйте линейную регрессию, дерево и SVM для регрессии.\n",
        "\n",
        "Какой набор моделей дает лучший результат? Попробуйте улучшить его, перебрав несколько гиперпараметров (как у базовой модели, так и у ансамбля)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HnkGgBpqfgI"
      },
      "source": [
        "## Простой стекинг своими руками (2 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "id": "in4yMYq1qVei"
      },
      "outputs": [],
      "source": [
        "class StackingRegressionSolver:\n",
        "    def __init__(self, base_estimators: list, meta_estimator):\n",
        "        self._base_estimators = base_estimators\n",
        "        self._meta_estimator = meta_estimator\n",
        "\n",
        "    def _fit_base(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
        "        for estimator in self._base_estimators:\n",
        "            estimator.fit(X, y)\n",
        "\n",
        "    def _predict_base(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        return np.array([estimator.predict(X) for estimator in self._base_estimators]).T\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
        "        self._fit_base(X, y)\n",
        "        meta_features = self._predict_base(X)\n",
        "        self._meta_estimator.fit(meta_features, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        meta_features = self._predict_base(X)\n",
        "        return self._meta_estimator.predict(meta_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error as mse, r2_score\n",
        "def draw_metrics(y_pred_test, y_pred_train, y_test, y_train):\n",
        "    print('Test\\nMSE & RMSE & R2')\n",
        "    print(mse(y_test, y_pred_test), mse(y_test, y_pred_test, squared=False), r2_score(y_test, y_pred_test))\n",
        "    print('Train\\nMSE & RMSE & R2')\n",
        "    print(mse(y_train, y_pred_train), mse(y_train, y_pred_train, squared=False), r2_score(y_train, y_pred_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "id": "OnrpvxiHccHL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3890.2547370070424 62.37190663277051 0.023805188373941855\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "91.8492922542257 9.583803642303284 0.9323868757421496\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression, ElasticNet\n",
        "from sklearn.svm import LinearSVR, SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "linreg = LinearRegression()\n",
        "svm = LinearSVR()\n",
        "tree = DecisionTreeRegressor()\n",
        "\n",
        "stacking_regressor = StackingRegressionSolver([svm, tree], linreg)\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "99115.12759977931 314.82555105928 -23.871295032725293\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "91.84929225422567 9.583803642303282 0.9323868757421496\n"
          ]
        }
      ],
      "source": [
        "stacking_regressor = StackingRegressionSolver([svm, linreg], DecisionTreeRegressor())\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3882.6375607858618 62.31081415601839 0.025716592230255575\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "91.84929225422567 9.583803642303282 0.9323868757421496\n"
          ]
        }
      ],
      "source": [
        "stacking_regressor = StackingRegressionSolver([tree], LinearRegression())\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3.8532945356168e+22 196298103292.33444 -9.669202629723195e+18\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "586.8134234767188 24.22423215453317 0.5680283653369075\n"
          ]
        }
      ],
      "source": [
        "stacking_regressor = StackingRegressionSolver([svm, LinearRegression()], LinearRegression())\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "99260.08859828088 315.05569126470465 -23.90767058759043\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "96.5819859238835 9.827613439888827 0.928902992553641\n"
          ]
        }
      ],
      "source": [
        "stacking_regressor = StackingRegressionSolver([linreg], tree)\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3920.250539590752 62.611904136439996 0.016278239926523552\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "91.8492922542257 9.583803642303284 0.9323868757421496\n"
          ]
        }
      ],
      "source": [
        "stacking_regressor = StackingRegressionSolver([svm, tree, linreg], LinearRegression())\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Самый лучший вариант получился с базой: SVM, Tree(SVM, LinReg) и Метамоделью: LinReg(LinReg) . Давайте попробуем перебрать параметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {},
      "outputs": [],
      "source": [
        "linreg = LinearRegression()\n",
        "svm = LinearSVR()\n",
        "tree = DecisionTreeRegressor(max_depth=5, min_samples_split=300, min_samples_leaf=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3.8532952323748776e+22 196298121039.78168 -9.669204378121865e+18\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "586.8134234822063 24.224232154646437 0.5680283653328679\n"
          ]
        }
      ],
      "source": [
        "stacking_regressor = StackingRegressionSolver([svm, LinearRegression()], LinearRegression())\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3726.6633890360044 61.04640357167656 0.06485572000033679\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "1070.7447290176099 32.722236002718546 0.21179146148319583\n"
          ]
        }
      ],
      "source": [
        "stacking_regressor = StackingRegressionSolver([svm, tree], linreg)\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "y_pred = stacking_regressor.predict(X_test)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(SVM, Linear) + (Linear) - очень сильно переобучается в сравнении с моделькой (SVM, tree) + (Linear), хотя последняя даже показывает лучше результаты"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tISuwHbhqjGN"
      },
      "source": [
        "## Использование встроенной модели стекинга (0.5 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {
        "id": "PgHoaeW0nWGh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3778.346975317163 61.46825990149032 0.051886582454164\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "1084.764667006218 32.93576577227586 0.2014709485424171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "estimators = [('svm', SVR()),\n",
        "              ('tree', DecisionTreeRegressor(max_depth=5, min_samples_split=500))]\n",
        "\n",
        "stacking_regressor = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y95u9XcqmeP"
      },
      "source": [
        "## Блендинг (0.5 балла)\n",
        "\n",
        "Реализуйте схему блендинга. Для этого разбейте **тестовую** выборку на *валидационную* и *тестовую* части, при необходимости также доработайте код класса `StackingRegressionSolver`. Используйте для обучения базовых моделей обучающую выборку, а для обучения метамодели - валидационную.\n",
        "\n",
        "Как изменилось качество? Как вы думаете, правдоподобнее ли выглядит такой результат?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "id": "t6JPX4o4rBP1"
      },
      "outputs": [],
      "source": [
        "class StackingRegressionSolver:\n",
        "    def __init__(self, base_estimators: list, meta_estimator):\n",
        "        self._base_estimators = base_estimators\n",
        "        self._meta_estimator = meta_estimator\n",
        "\n",
        "    def _fit_base(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
        "        for estimator in self._base_estimators:\n",
        "            estimator.fit(X, y)\n",
        "\n",
        "    def _predict_base(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        return np.array([estimator.predict(X) for estimator in self._base_estimators]).T\n",
        "\n",
        "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series, X_val: pd.DataFrame, y_val: pd.Series):\n",
        "        self._fit_base(X_train, y_train)\n",
        "        meta_features = self._predict_base(X_val)\n",
        "        self._meta_estimator.fit(meta_features, y_val)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        meta_features = self._predict_base(X)\n",
        "        return self._meta_estimator.predict(meta_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")\n",
        "\n",
        "path = \"C:/Users/Дмитрий/Desktop/hw_10/ml-fall22/10. Ensembles/prepaired_data.csv\"\n",
        "prepaired_data = pd.read_csv(path)\n",
        "X_train, X_test = prepaired_data.query('split==\"train\"'), prepaired_data.query('split==\"test\"')\n",
        "y_train, y_test = prepaired_data.query('split==\"train\"').target, prepaired_data.query('split==\"test\"').target\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.5, random_state=42)\n",
        "\n",
        "trans = ColumnTransformer(\n",
        "    [('num', StandardScaler(with_mean=False), [1,2,3,4]),\n",
        "     ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), [0,5,6,7,8,9])])\n",
        "     \n",
        "X_train= trans.fit_transform(X_train)\n",
        "X_val = trans.transform(X_val)\n",
        "X_test = trans.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3800.665244650831 61.64953564018817 0.04628618345696067\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "1114.008160260092 33.376760781419335 0.20126849250567957\n"
          ]
        }
      ],
      "source": [
        "linreg = LinearRegression()\n",
        "svm = LinearSVR()\n",
        "tree = DecisionTreeRegressor(max_depth=4, min_samples_split=300, min_samples_leaf=5)\n",
        "\n",
        "stacking_regressor = StackingRegressionSolver([svm, tree], linreg)\n",
        "stacking_regressor.fit(X_train, y_train, X_val, y_val)\n",
        "y_pred = stacking_regressor.predict(X_test)\n",
        "y_pred_test = stacking_regressor.predict(X_test)\n",
        "y_pred_train = stacking_regressor.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Качество незначительно лучше. Думаю, что такой результат более реальный, потому что валидация это более независимая методика."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu3-DYDlqKhT"
      },
      "source": [
        "# Бэггинг (максимум 3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIJY9_baafxr"
      },
      "source": [
        "В этой секции аналогично нужно решить задачу при помощи бэггинга - сначала написанного самостоятельно, а затем взятого из sklearn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWrKsOxerRUC"
      },
      "source": [
        "## Бэггинг своими руками (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frsguFTtawet"
      },
      "source": [
        "Решите задачу, используя в качестве базовой модели линейную регрессию, дерево и SVM. Какой из алгоритмов в качестве базовой модели дает лучший результат? Почему, как вы думаете?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {
        "id": "M6TGRabcnSxG"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "import random\n",
        "\n",
        "class BaggingRegressionSolver:\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_estimator_ctor,\n",
        "        max_samples: float = 1,\n",
        "        n_estimators: int = 10,\n",
        "        sample_random_state=42,\n",
        "        **model_kwargs\n",
        "    ):\n",
        "        if max_samples < 0 or max_samples > 1:\n",
        "            raise ValueError\n",
        "        self._estimators = [\n",
        "            base_estimator_ctor(**model_kwargs) for _ in range(n_estimators)\n",
        "        ]\n",
        "        self._max_samples = max_samples\n",
        "        self._random_state = sample_random_state\n",
        "\n",
        "    def _sample_data(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "        x_i = X.sample(frac=self._max_samples,)\n",
        "        y_i = y.loc[x_i.index]\n",
        "        return x_i, y_i\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
        "        for estimator in self._estimators:\n",
        "            x_i, y_i = self._sample_data(X, y)\n",
        "            estimator.fit(x_i, y_i)\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return np.median([estimator.predict(X) for estimator in self._estimators], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import set_config\n",
        "\n",
        "path = \"C:/Users/Дмитрий/Desktop/hw_10/ml-fall22/10. Ensembles/prepaired_data.csv\"\n",
        "prepaired_data = pd.read_csv(path)\n",
        "X_train, X_test = prepaired_data.query('split==\"train\"'), prepaired_data.query('split==\"test\"')\n",
        "y_train, y_test = prepaired_data.query('split==\"train\"').target, prepaired_data.query('split==\"test\"').target\n",
        "\n",
        "trans = ColumnTransformer(\n",
        "    [('num', StandardScaler(with_mean=False), [1,2,3,4]),\n",
        "     ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), [0,5,6,7,8,9])])\n",
        "\n",
        "X_train= trans.fit_transform(X_train)\n",
        "X_test = trans.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {
        "id": "R7E2FbSHa_Hf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "7.391234064315752e+21 85972286606.29977 -1.8547074248021816e+18\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "586.8086990702634 24.224134640276905 0.5680318431196195\n",
            "Test\n",
            "MSE & RMSE & R2\n",
            "3890.147267546314 62.37104510545189 0.02383215605011313\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "91.84929225422567 9.583803642303282 0.9323868757421496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3920.783493931441 62.61616000627507 0.016144503886755923\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "1233.9571958867957 35.1277268818635 0.09164568210895307\n"
          ]
        }
      ],
      "source": [
        "base_models = [LinearRegression, DecisionTreeRegressor, LinearSVR]\n",
        "\n",
        "for base_model in base_models:\n",
        "    \n",
        "    bagging_Regression = BaggingRegressionSolver(base_model)\n",
        "    bagging_Regression.fit(X_train, y_train)\n",
        "    y_pred_test = bagging_Regression.predict(X_test)\n",
        "    y_pred_train = bagging_Regression.predict(X_train)\n",
        "    draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVM показал себя лучше всех. Переобучился меньше, чем деревья. Про линейную регрессию вообще молчу))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLVRU23TrTfj"
      },
      "source": [
        "## Использование встроенной модели бэггинга (1 балл)\n",
        "\n",
        "Решите задачу, используя:\n",
        "- `sklearn.ensemble.BaggingRegressor`. В качестве базовой модели попробуйте линейную регрессию, дерево и SVM\n",
        "- `sklearn.ensemble.RandomForestRegressor`\n",
        "\n",
        "Какая модель дает лучший результат? Попробуйте улучшить его, перебрав несколько гиперпараметров (как у базовой модели, так и у ансамбля).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugjjfpES2kk1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base: LinRegr\n",
            "Test\n",
            "3.757319227817121e+23 612969756824.6838 -9.428368535680444e+19\n",
            "Train\n",
            "4.7021861075999215e+23 685724879787.7996 -3.461425622058233e+20\n",
            "\n",
            "Base: Tree\n",
            "Test\n",
            "3770.171785330131 61.40172461201828 0.053938010596768726\n",
            "Train\n",
            "286.4915406279927 16.926060989728022 0.7891046554644269\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base: SVM\n",
            "Test\n",
            "3914.5447899931232 62.56632312988452 0.01771000301922221\n",
            "Train\n",
            "1224.3260815924152 34.99037126971383 0.09873544525840772\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingRegressor, BaggingRegressor, RandomForestRegressor\n",
        "\n",
        "base_models = [(\"LinRegr\", LinearRegression()), ('Tree', DecisionTreeRegressor()), ('SVM', LinearSVR())]\n",
        "\n",
        "for name, model in base_models:\n",
        "    bagging_Regression = BaggingRegressor(model)\n",
        "    bagging_Regression.fit(X_train, y_train)\n",
        "    print(f'Base: {name}')\n",
        "    y_pred_test = bagging_Regression.predict(X_test)\n",
        "    y_pred_train = bagging_Regression.predict(X_train)\n",
        "    draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "MSE & RMSE & R2\n",
            "3718.1378635336196 60.976535351999296 0.06699505902167213\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "226.72217524188144 15.057296412101392 0.8331027465708729\n"
          ]
        }
      ],
      "source": [
        "RandomForestRegressorion = RandomForestRegressor()\n",
        "RandomForestRegressorion.fit(X_train, y_train)\n",
        "y_pred_test = RandomForestRegressorion.predict(X_test)\n",
        "y_pred_train = RandomForestRegressorion.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ООООО, это то, что надо. Давайте попробуем параметры перебрать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params: {'max_depth': None, 'max_features': 0.5, 'max_samples': 0.5, 'n_estimators': 200}\n",
            "Test\n",
            "3706.8078753069944 60.883559975637056 0.06983813138333572\n",
            "Train\n",
            "440.19634815350616 20.98085670685318 0.6759577602059781\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'max_depth' : [None] + [1, 20],\n",
        "    \"max_features\": np.linspace(0.5, 1, 2),\n",
        "    'max_samples' : np.linspace(0.5, 1, 2),\n",
        "    'n_estimators' : [1, 200]\n",
        "}\n",
        "\n",
        "search_params = GridSearchCV(RandomForestRegressorion, params, scoring=\"r2\")\n",
        "search_params.fit(X_train, y_train)\n",
        "print(f\"Best params: {search_params.best_params_}\")\n",
        "y_pred_test = search_params.predict(X_test)\n",
        "y_pred_train = search_params.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-jNmNEEqMU6"
      },
      "source": [
        "# Бустинг (максимум 3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd9LV-ot4cke"
      },
      "source": [
        "## Бустинг своими руками (2 балла)\n",
        "\n",
        "Решите задачу при помощи алгоритма бустинга, используя в качестве базовой модели:\n",
        "- Линейную регрессию\n",
        "- Дерево\n",
        "- Случайный лес\n",
        "\n",
        "Какая модель дает лучший результат? Попробуйте улучшить его, перебрав несколько гиперпараметров (как у базовой модели, так и у ансамбля)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "id": "Sx68FEOxmxw1"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from collections import deque\n",
        "from typing import Tuple\n",
        "\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "\n",
        "class Loss(ABC):\n",
        "    \"\"\"\n",
        "    Базовый класс для функции потерь\n",
        "    \"\"\"\n",
        "    @abstractmethod\n",
        "    def forward(self, y_true: pd.Series, y_pred: pd.Series) -> float:\n",
        "        \"\"\"\n",
        "        Метод, вычисляющий значение функции потерь\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def backward(self, y_true: pd.Series, y_pred: pd.Series) -> pd.Series:\n",
        "        \"\"\"\n",
        "        Метод, вычисляющий значение градиента функции потерь по предсказаниям модели\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class MSELoss(Loss): \n",
        "    def forward(self, y_pred: pd.Series, y_true: pd.Series) -> float:  # посчитаем значение ошибки\n",
        "        return ((y_pred - y_true) ** 2).mean()\n",
        "\n",
        "    def backward(self, y_pred: pd.Series, y_true: pd.Series) -> pd.Series:  # посчитаем производную по выходам модели\n",
        "        return y_true - y_pred\n",
        "\n",
        "\n",
        "class GradientBoostingRegressionSolver:\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_estimator_ctor,\n",
        "        n_estimators: int = 10,\n",
        "        loss: Loss = MSELoss(),\n",
        "        learning_rate: float = 0.1,\n",
        "        early_stopping: int = 5,\n",
        "        **model_kwargs\n",
        "    ):\n",
        "        if early_stopping < 0:\n",
        "            raise ValueError\n",
        "\n",
        "        self._ctor = base_estimator_ctor\n",
        "        self._kwargs = model_kwargs\n",
        "        self._n_estimators = n_estimators\n",
        "        self._estimators = []\n",
        "        self._early_stopping = early_stopping\n",
        "        self._loss = loss\n",
        "        self._lr = learning_rate\n",
        "        self._random_state = 42\n",
        "\n",
        "    def _sample_data(self, X: pd.DataFrame, y: pd.Series, frac: float) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "        x_sample = X.sample(frac=frac, random_state=self._random_state)\n",
        "        y_sample = y.loc[x_sample.index]\n",
        "        return x_sample, y_sample\n",
        "\n",
        "    def _split_data(self, X: pd.DataFrame, y: pd.Series, val_size: float) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
        "        x_val, y_val = self._sample_data(X, y, val_size)\n",
        "        x_train, y_train = X[~X.index.isin(x_val.index)], y[~y.index.isin(y_val.index)]\n",
        "        return x_train, x_val, y_train, y_val\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return np.sum([estimator.predict(X) for estimator in self._estimators], axis=0)\n",
        "        \n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, val_size: float = 0.1):\n",
        "        x_train, x_val, y_train, y_val = self._split_data(X, y, val_size)  # Хотим получить валидационную выборку, не тратя на это время снаружи\n",
        "        base_estimator = DummyRegressor()  # Создадим и обучим базовую модель\n",
        "        base_estimator.fit(x_train, y_train)\n",
        "        self._estimators.append(base_estimator)  # Добавим базовую модель в список моделей\n",
        "\n",
        "        y_pred_train, y_pred_val = base_estimator.predict(x_train), base_estimator.predict(x_val)  # Посчитаем предсказания как на обучающей, так и на валидационной выборках\n",
        "        train_loss, val_loss = self._loss.forward(y_train, y_pred_train), self._loss.forward(y_val, y_pred_val)  # Посчитаем значение функции потерь для обучения и валидации\n",
        "        balance = -self._lr * self._loss.backward(y_train, y_pred_train)  # Посчитаем остатки, используя градиент функции потерь\n",
        "        # print(f'train loss: {train_loss}, val loss: {val_loss}')\n",
        "\n",
        "        prev_val_loss = val_loss\n",
        "        k = 0\n",
        "        for i in range(self._n_estimators - 1):\n",
        "            estimator = self._ctor(**self._kwargs)  # Создадим очередную модель\n",
        "            # 1. Обучим её и добавим в список моделей\n",
        "            estimator.fit(x_train, balance)\n",
        "            self._estimators.append(estimator)\n",
        "            # 2. Предскажем ВСЕМ ансамблем данные из обучающей выборки, то же самое сделаем для валидационной\n",
        "            y_pred_train, y_pred_val = self.predict(x_train), self.predict(x_val)\n",
        "            # 3. Посчитаем значения функции потерь (на обучении и валидации)\n",
        "            train_loss, val_loss = self._loss.forward(y_train, y_pred_train), self._loss.forward(y_val, y_pred_val)\n",
        "            # 4. Обновим остатки для обучающей выборки\n",
        "            balance = -self._lr * self._loss.backward(y_train, y_pred_train)\n",
        "            # print(f'train loss: {train_loss}, val loss: {val_loss}')\n",
        "            # Если валидационный лосс несколько (self._early_stopping) шагов подряд не уменьшается, то остановим обучение\n",
        "            if val_loss >= prev_val_loss:\n",
        "                k += 1\n",
        "            if k >= self._early_stopping:\n",
        "                break\n",
        "            prev_val_loss = val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_Fgwz-JfRw6"
      },
      "source": [
        "Вопросы на дополнительный балл:\n",
        "- Почему градиент по ответам мы берем со знаком минус?\n",
        "- Почему в обучении мы домножаем на `learning_rate`, а в предсказаниях этого не делаем?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IWQSDxWoc2Xq"
      },
      "source": [
        "Мы же минимизируем функцию, а не максимизируем. Нам же нужно найти минимум, а не максимум. Именно поэтому мы градиент по ответам берём со знаком минус. Градиент же по дефолту указывает нам на скореейшее возрастание функции, но если мы этот вектор умножим на (-1), то получим как раз то, что нам нужно. \n",
        "\n",
        "Learning_rate - в самом названии таится вся разгадка! Он указывает нам на шаг, при котором модель учится, чтобы найти свой минимум. Если он будет большой - мы его проскочим, если он будет слишком маленьким - будем долго до него идти. А зачем нам это делать в предсказаниях? Мы уже обучили модель, нашли всё, что нам нужно на наших данных. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LinearRegression\n",
            "Test\n",
            "MSE & RMSE & R2\n",
            "1.1496962966714456e+23 339071717586.62585 -2.8849718993461555e+19\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "3.2715562729088997e+22 180874439125.84497 -2.4082944502663033e+19\n",
            "DecisionTreeRegressor\n",
            "Test\n",
            "MSE & RMSE & R2\n",
            "3729.2147492278036 61.06729688816923 0.06421549853665443\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "344.5039652297996 18.560818010793586 0.7463999031812574\n",
            "RandomForestRegressor\n",
            "Test\n",
            "MSE & RMSE & R2\n",
            "3707.370833724175 60.88818303845316 0.06969686631892102\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "466.3364070681017 21.594823617434383 0.6567152488253989\n"
          ]
        }
      ],
      "source": [
        "base_models = [LinearRegression, DecisionTreeRegressor, RandomForestRegressor]\n",
        "\n",
        "for base_model in base_models:\n",
        "    model = GradientBoostingRegressionSolver(base_model)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(base_model.__name__)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iul0dgvdqOIa"
      },
      "source": [
        "# Catboost (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIMRGkhP5KOk"
      },
      "source": [
        "Решите эту же задачу при помощи `catboost`, не перебирая гиперпараметры. Насколько лучше или хуже справился катбуст? В качестве эксперимента также попробуйте закинуть в него данные без предобработки (разумеется, выкинув ненужные колонки). Изменилось ли качество? Каким образом?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {
        "id": "e9ewnPfYqP5P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.054298\n",
            "0:\tlearn: 36.6270981\ttotal: 6.18ms\tremaining: 6.18s\n",
            "1:\tlearn: 36.4101270\ttotal: 13ms\tremaining: 6.48s\n",
            "2:\tlearn: 36.2219716\ttotal: 19.6ms\tremaining: 6.53s\n",
            "3:\tlearn: 36.0025654\ttotal: 25.9ms\tremaining: 6.45s\n",
            "4:\tlearn: 35.8149619\ttotal: 32.3ms\tremaining: 6.42s\n",
            "5:\tlearn: 35.7441449\ttotal: 38.9ms\tremaining: 6.45s\n",
            "6:\tlearn: 35.5506920\ttotal: 45.3ms\tremaining: 6.42s\n",
            "7:\tlearn: 35.4105632\ttotal: 51.8ms\tremaining: 6.42s\n",
            "8:\tlearn: 35.3111169\ttotal: 58.7ms\tremaining: 6.46s\n",
            "9:\tlearn: 35.2391904\ttotal: 65ms\tremaining: 6.44s\n",
            "10:\tlearn: 35.1176114\ttotal: 71.3ms\tremaining: 6.41s\n",
            "11:\tlearn: 34.9984703\ttotal: 77.6ms\tremaining: 6.39s\n",
            "12:\tlearn: 34.9218486\ttotal: 84.2ms\tremaining: 6.4s\n",
            "13:\tlearn: 34.8429712\ttotal: 90.7ms\tremaining: 6.39s\n",
            "14:\tlearn: 34.7080114\ttotal: 97ms\tremaining: 6.37s\n",
            "15:\tlearn: 34.6480272\ttotal: 103ms\tremaining: 6.36s\n",
            "16:\tlearn: 34.4959077\ttotal: 110ms\tremaining: 6.35s\n",
            "17:\tlearn: 34.4172237\ttotal: 116ms\tremaining: 6.32s\n",
            "18:\tlearn: 34.3459168\ttotal: 122ms\tremaining: 6.32s\n",
            "19:\tlearn: 34.2947599\ttotal: 129ms\tremaining: 6.3s\n",
            "20:\tlearn: 34.2034313\ttotal: 135ms\tremaining: 6.28s\n",
            "21:\tlearn: 34.0789283\ttotal: 141ms\tremaining: 6.27s\n",
            "22:\tlearn: 33.9739711\ttotal: 148ms\tremaining: 6.27s\n",
            "23:\tlearn: 33.9041720\ttotal: 154ms\tremaining: 6.28s\n",
            "24:\tlearn: 33.8092201\ttotal: 161ms\tremaining: 6.27s\n",
            "25:\tlearn: 33.7650647\ttotal: 168ms\tremaining: 6.28s\n",
            "26:\tlearn: 33.7227844\ttotal: 174ms\tremaining: 6.28s\n",
            "27:\tlearn: 33.6735805\ttotal: 180ms\tremaining: 6.26s\n",
            "28:\tlearn: 33.5948937\ttotal: 187ms\tremaining: 6.25s\n",
            "29:\tlearn: 33.5273646\ttotal: 193ms\tremaining: 6.25s\n",
            "30:\tlearn: 33.4710179\ttotal: 200ms\tremaining: 6.26s\n",
            "31:\tlearn: 33.3659991\ttotal: 207ms\tremaining: 6.26s\n",
            "32:\tlearn: 33.2825394\ttotal: 214ms\tremaining: 6.27s\n",
            "33:\tlearn: 33.2328012\ttotal: 221ms\tremaining: 6.28s\n",
            "34:\tlearn: 33.1482931\ttotal: 231ms\tremaining: 6.37s\n",
            "35:\tlearn: 33.0678342\ttotal: 239ms\tremaining: 6.41s\n",
            "36:\tlearn: 33.0073221\ttotal: 248ms\tremaining: 6.46s\n",
            "37:\tlearn: 32.9275169\ttotal: 256ms\tremaining: 6.49s\n",
            "38:\tlearn: 32.8767462\ttotal: 263ms\tremaining: 6.48s\n",
            "39:\tlearn: 32.8258454\ttotal: 269ms\tremaining: 6.46s\n",
            "40:\tlearn: 32.7798997\ttotal: 276ms\tremaining: 6.46s\n",
            "41:\tlearn: 32.7279233\ttotal: 283ms\tremaining: 6.45s\n",
            "42:\tlearn: 32.6958963\ttotal: 289ms\tremaining: 6.44s\n",
            "43:\tlearn: 32.6629386\ttotal: 295ms\tremaining: 6.42s\n",
            "44:\tlearn: 32.5951204\ttotal: 302ms\tremaining: 6.4s\n",
            "45:\tlearn: 32.5540066\ttotal: 308ms\tremaining: 6.39s\n",
            "46:\tlearn: 32.5186972\ttotal: 314ms\tremaining: 6.37s\n",
            "47:\tlearn: 32.4774149\ttotal: 321ms\tremaining: 6.37s\n",
            "48:\tlearn: 32.4284464\ttotal: 327ms\tremaining: 6.35s\n",
            "49:\tlearn: 32.3531014\ttotal: 334ms\tremaining: 6.34s\n",
            "50:\tlearn: 32.3269834\ttotal: 340ms\tremaining: 6.33s\n",
            "51:\tlearn: 32.2819312\ttotal: 346ms\tremaining: 6.31s\n",
            "52:\tlearn: 32.2349671\ttotal: 353ms\tremaining: 6.31s\n",
            "53:\tlearn: 32.1663608\ttotal: 359ms\tremaining: 6.29s\n",
            "54:\tlearn: 32.1203201\ttotal: 366ms\tremaining: 6.28s\n",
            "55:\tlearn: 32.0515534\ttotal: 372ms\tremaining: 6.27s\n",
            "56:\tlearn: 32.0091148\ttotal: 378ms\tremaining: 6.26s\n",
            "57:\tlearn: 31.9379304\ttotal: 384ms\tremaining: 6.24s\n",
            "58:\tlearn: 31.8636649\ttotal: 391ms\tremaining: 6.23s\n",
            "59:\tlearn: 31.8335237\ttotal: 397ms\tremaining: 6.22s\n",
            "60:\tlearn: 31.7652579\ttotal: 404ms\tremaining: 6.22s\n",
            "61:\tlearn: 31.7399502\ttotal: 411ms\tremaining: 6.22s\n",
            "62:\tlearn: 31.6685419\ttotal: 418ms\tremaining: 6.21s\n",
            "63:\tlearn: 31.6032663\ttotal: 425ms\tremaining: 6.22s\n",
            "64:\tlearn: 31.5770234\ttotal: 432ms\tremaining: 6.21s\n",
            "65:\tlearn: 31.5414509\ttotal: 440ms\tremaining: 6.22s\n",
            "66:\tlearn: 31.4887655\ttotal: 446ms\tremaining: 6.21s\n",
            "67:\tlearn: 31.4496615\ttotal: 453ms\tremaining: 6.21s\n",
            "68:\tlearn: 31.3983830\ttotal: 459ms\tremaining: 6.2s\n",
            "69:\tlearn: 31.3515926\ttotal: 466ms\tremaining: 6.19s\n",
            "70:\tlearn: 31.2960370\ttotal: 472ms\tremaining: 6.18s\n",
            "71:\tlearn: 31.2545726\ttotal: 478ms\tremaining: 6.17s\n",
            "72:\tlearn: 31.2407748\ttotal: 485ms\tremaining: 6.15s\n",
            "73:\tlearn: 31.2183473\ttotal: 491ms\tremaining: 6.15s\n",
            "74:\tlearn: 31.1935033\ttotal: 497ms\tremaining: 6.13s\n",
            "75:\tlearn: 31.1789149\ttotal: 504ms\tremaining: 6.12s\n",
            "76:\tlearn: 31.1558250\ttotal: 510ms\tremaining: 6.11s\n",
            "77:\tlearn: 31.1051127\ttotal: 517ms\tremaining: 6.12s\n",
            "78:\tlearn: 31.0889230\ttotal: 524ms\tremaining: 6.11s\n",
            "79:\tlearn: 31.0262561\ttotal: 531ms\tremaining: 6.1s\n",
            "80:\tlearn: 31.0059484\ttotal: 537ms\tremaining: 6.1s\n",
            "81:\tlearn: 30.9647558\ttotal: 544ms\tremaining: 6.09s\n",
            "82:\tlearn: 30.9467763\ttotal: 551ms\tremaining: 6.09s\n",
            "83:\tlearn: 30.9251578\ttotal: 558ms\tremaining: 6.08s\n",
            "84:\tlearn: 30.9014393\ttotal: 564ms\tremaining: 6.07s\n",
            "85:\tlearn: 30.8491042\ttotal: 571ms\tremaining: 6.07s\n",
            "86:\tlearn: 30.8342319\ttotal: 578ms\tremaining: 6.07s\n",
            "87:\tlearn: 30.8180129\ttotal: 585ms\tremaining: 6.06s\n",
            "88:\tlearn: 30.7817927\ttotal: 591ms\tremaining: 6.05s\n",
            "89:\tlearn: 30.7469544\ttotal: 598ms\tremaining: 6.04s\n",
            "90:\tlearn: 30.7044861\ttotal: 605ms\tremaining: 6.04s\n",
            "91:\tlearn: 30.6902403\ttotal: 611ms\tremaining: 6.03s\n",
            "92:\tlearn: 30.6786701\ttotal: 617ms\tremaining: 6.02s\n",
            "93:\tlearn: 30.6241555\ttotal: 624ms\tremaining: 6.01s\n",
            "94:\tlearn: 30.5765984\ttotal: 630ms\tremaining: 6s\n",
            "95:\tlearn: 30.5574639\ttotal: 636ms\tremaining: 5.99s\n",
            "96:\tlearn: 30.5393673\ttotal: 643ms\tremaining: 5.98s\n",
            "97:\tlearn: 30.4955115\ttotal: 649ms\tremaining: 5.97s\n",
            "98:\tlearn: 30.4750758\ttotal: 656ms\tremaining: 5.97s\n",
            "99:\tlearn: 30.4650788\ttotal: 663ms\tremaining: 5.96s\n",
            "100:\tlearn: 30.4311817\ttotal: 670ms\tremaining: 5.97s\n",
            "101:\tlearn: 30.3750285\ttotal: 677ms\tremaining: 5.96s\n",
            "102:\tlearn: 30.3571123\ttotal: 684ms\tremaining: 5.96s\n",
            "103:\tlearn: 30.3472318\ttotal: 690ms\tremaining: 5.95s\n",
            "104:\tlearn: 30.2973661\ttotal: 697ms\tremaining: 5.94s\n",
            "105:\tlearn: 30.2582941\ttotal: 703ms\tremaining: 5.93s\n",
            "106:\tlearn: 30.2196683\ttotal: 710ms\tremaining: 5.92s\n",
            "107:\tlearn: 30.2015715\ttotal: 716ms\tremaining: 5.92s\n",
            "108:\tlearn: 30.1913904\ttotal: 723ms\tremaining: 5.91s\n",
            "109:\tlearn: 30.1681068\ttotal: 729ms\tremaining: 5.9s\n",
            "110:\tlearn: 30.1407754\ttotal: 735ms\tremaining: 5.89s\n",
            "111:\tlearn: 30.1006841\ttotal: 742ms\tremaining: 5.88s\n",
            "112:\tlearn: 30.0549406\ttotal: 748ms\tremaining: 5.87s\n",
            "113:\tlearn: 30.0412455\ttotal: 754ms\tremaining: 5.86s\n",
            "114:\tlearn: 30.0291298\ttotal: 758ms\tremaining: 5.83s\n",
            "115:\tlearn: 30.0051443\ttotal: 765ms\tremaining: 5.83s\n",
            "116:\tlearn: 29.9851340\ttotal: 771ms\tremaining: 5.82s\n",
            "117:\tlearn: 29.9633118\ttotal: 777ms\tremaining: 5.81s\n",
            "118:\tlearn: 29.9331280\ttotal: 784ms\tremaining: 5.8s\n",
            "119:\tlearn: 29.8844079\ttotal: 790ms\tremaining: 5.79s\n",
            "120:\tlearn: 29.8723808\ttotal: 797ms\tremaining: 5.79s\n",
            "121:\tlearn: 29.8556933\ttotal: 803ms\tremaining: 5.78s\n",
            "122:\tlearn: 29.8390045\ttotal: 809ms\tremaining: 5.77s\n",
            "123:\tlearn: 29.8302888\ttotal: 816ms\tremaining: 5.76s\n",
            "124:\tlearn: 29.8190180\ttotal: 822ms\tremaining: 5.75s\n",
            "125:\tlearn: 29.8084867\ttotal: 829ms\tremaining: 5.75s\n",
            "126:\tlearn: 29.7979691\ttotal: 835ms\tremaining: 5.74s\n",
            "127:\tlearn: 29.7477958\ttotal: 843ms\tremaining: 5.74s\n",
            "128:\tlearn: 29.7064661\ttotal: 849ms\tremaining: 5.73s\n",
            "129:\tlearn: 29.6957470\ttotal: 857ms\tremaining: 5.73s\n",
            "130:\tlearn: 29.6664085\ttotal: 864ms\tremaining: 5.73s\n",
            "131:\tlearn: 29.6566994\ttotal: 871ms\tremaining: 5.72s\n",
            "132:\tlearn: 29.6211751\ttotal: 878ms\tremaining: 5.72s\n",
            "133:\tlearn: 29.6024257\ttotal: 885ms\tremaining: 5.72s\n",
            "134:\tlearn: 29.5839858\ttotal: 891ms\tremaining: 5.71s\n",
            "135:\tlearn: 29.5411565\ttotal: 898ms\tremaining: 5.7s\n",
            "136:\tlearn: 29.4988792\ttotal: 905ms\tremaining: 5.7s\n",
            "137:\tlearn: 29.4627369\ttotal: 911ms\tremaining: 5.69s\n",
            "138:\tlearn: 29.4429710\ttotal: 918ms\tremaining: 5.68s\n",
            "139:\tlearn: 29.4018534\ttotal: 924ms\tremaining: 5.68s\n",
            "140:\tlearn: 29.3931545\ttotal: 931ms\tremaining: 5.67s\n",
            "141:\tlearn: 29.3829196\ttotal: 938ms\tremaining: 5.67s\n",
            "142:\tlearn: 29.3607776\ttotal: 945ms\tremaining: 5.66s\n",
            "143:\tlearn: 29.3327999\ttotal: 952ms\tremaining: 5.66s\n",
            "144:\tlearn: 29.3219284\ttotal: 958ms\tremaining: 5.65s\n",
            "145:\tlearn: 29.2933721\ttotal: 964ms\tremaining: 5.64s\n",
            "146:\tlearn: 29.2790495\ttotal: 971ms\tremaining: 5.63s\n",
            "147:\tlearn: 29.2634995\ttotal: 977ms\tremaining: 5.63s\n",
            "148:\tlearn: 29.2348991\ttotal: 984ms\tremaining: 5.62s\n",
            "149:\tlearn: 29.2287818\ttotal: 990ms\tremaining: 5.61s\n",
            "150:\tlearn: 29.1994114\ttotal: 997ms\tremaining: 5.6s\n",
            "151:\tlearn: 29.1765897\ttotal: 1s\tremaining: 5.6s\n",
            "152:\tlearn: 29.1563819\ttotal: 1.01s\tremaining: 5.59s\n",
            "153:\tlearn: 29.1164575\ttotal: 1.02s\tremaining: 5.58s\n",
            "154:\tlearn: 29.1027789\ttotal: 1.02s\tremaining: 5.58s\n",
            "155:\tlearn: 29.0887697\ttotal: 1.03s\tremaining: 5.57s\n",
            "156:\tlearn: 29.0783117\ttotal: 1.03s\tremaining: 5.56s\n",
            "157:\tlearn: 29.0683859\ttotal: 1.04s\tremaining: 5.55s\n",
            "158:\tlearn: 29.0366676\ttotal: 1.05s\tremaining: 5.55s\n",
            "159:\tlearn: 28.9994763\ttotal: 1.05s\tremaining: 5.54s\n",
            "160:\tlearn: 28.9796434\ttotal: 1.06s\tremaining: 5.54s\n",
            "161:\tlearn: 28.9365488\ttotal: 1.07s\tremaining: 5.53s\n",
            "162:\tlearn: 28.9238335\ttotal: 1.08s\tremaining: 5.53s\n",
            "163:\tlearn: 28.9087392\ttotal: 1.08s\tremaining: 5.52s\n",
            "164:\tlearn: 28.8868744\ttotal: 1.09s\tremaining: 5.52s\n",
            "165:\tlearn: 28.8666181\ttotal: 1.1s\tremaining: 5.51s\n",
            "166:\tlearn: 28.8222178\ttotal: 1.1s\tremaining: 5.51s\n",
            "167:\tlearn: 28.7889676\ttotal: 1.11s\tremaining: 5.5s\n",
            "168:\tlearn: 28.7771413\ttotal: 1.12s\tremaining: 5.49s\n",
            "169:\tlearn: 28.7275178\ttotal: 1.12s\tremaining: 5.49s\n",
            "170:\tlearn: 28.6952368\ttotal: 1.13s\tremaining: 5.48s\n",
            "171:\tlearn: 28.6692979\ttotal: 1.14s\tremaining: 5.47s\n",
            "172:\tlearn: 28.6423096\ttotal: 1.14s\tremaining: 5.46s\n",
            "173:\tlearn: 28.6269159\ttotal: 1.15s\tremaining: 5.45s\n",
            "174:\tlearn: 28.5875651\ttotal: 1.16s\tremaining: 5.45s\n",
            "175:\tlearn: 28.5566596\ttotal: 1.16s\tremaining: 5.44s\n",
            "176:\tlearn: 28.5362927\ttotal: 1.17s\tremaining: 5.43s\n",
            "177:\tlearn: 28.5156104\ttotal: 1.18s\tremaining: 5.43s\n",
            "178:\tlearn: 28.5033023\ttotal: 1.18s\tremaining: 5.42s\n",
            "179:\tlearn: 28.4810331\ttotal: 1.19s\tremaining: 5.42s\n",
            "180:\tlearn: 28.4409029\ttotal: 1.2s\tremaining: 5.41s\n",
            "181:\tlearn: 28.4286009\ttotal: 1.2s\tremaining: 5.4s\n",
            "182:\tlearn: 28.4151140\ttotal: 1.21s\tremaining: 5.39s\n",
            "183:\tlearn: 28.3991153\ttotal: 1.22s\tremaining: 5.39s\n",
            "184:\tlearn: 28.3847238\ttotal: 1.22s\tremaining: 5.39s\n",
            "185:\tlearn: 28.3550419\ttotal: 1.23s\tremaining: 5.38s\n",
            "186:\tlearn: 28.3335957\ttotal: 1.24s\tremaining: 5.38s\n",
            "187:\tlearn: 28.3142879\ttotal: 1.24s\tremaining: 5.37s\n",
            "188:\tlearn: 28.3023157\ttotal: 1.25s\tremaining: 5.36s\n",
            "189:\tlearn: 28.2715494\ttotal: 1.25s\tremaining: 5.35s\n",
            "190:\tlearn: 28.2587140\ttotal: 1.26s\tremaining: 5.35s\n",
            "191:\tlearn: 28.2199592\ttotal: 1.27s\tremaining: 5.34s\n",
            "192:\tlearn: 28.2084037\ttotal: 1.28s\tremaining: 5.34s\n",
            "193:\tlearn: 28.1754247\ttotal: 1.28s\tremaining: 5.33s\n",
            "194:\tlearn: 28.1464620\ttotal: 1.29s\tremaining: 5.33s\n",
            "195:\tlearn: 28.1340871\ttotal: 1.3s\tremaining: 5.33s\n",
            "196:\tlearn: 28.1149038\ttotal: 1.3s\tremaining: 5.32s\n",
            "197:\tlearn: 28.0971055\ttotal: 1.31s\tremaining: 5.31s\n",
            "198:\tlearn: 28.0858842\ttotal: 1.32s\tremaining: 5.31s\n",
            "199:\tlearn: 28.0344544\ttotal: 1.32s\tremaining: 5.3s\n",
            "200:\tlearn: 28.0232412\ttotal: 1.33s\tremaining: 5.29s\n",
            "201:\tlearn: 28.0123259\ttotal: 1.34s\tremaining: 5.29s\n",
            "202:\tlearn: 28.0008009\ttotal: 1.34s\tremaining: 5.28s\n",
            "203:\tlearn: 27.9830853\ttotal: 1.35s\tremaining: 5.27s\n",
            "204:\tlearn: 27.9530774\ttotal: 1.37s\tremaining: 5.32s\n",
            "205:\tlearn: 27.9393404\ttotal: 1.38s\tremaining: 5.31s\n",
            "206:\tlearn: 27.9079419\ttotal: 1.39s\tremaining: 5.31s\n",
            "207:\tlearn: 27.8846773\ttotal: 1.39s\tremaining: 5.3s\n",
            "208:\tlearn: 27.8652153\ttotal: 1.4s\tremaining: 5.29s\n",
            "209:\tlearn: 27.8489395\ttotal: 1.41s\tremaining: 5.29s\n",
            "210:\tlearn: 27.8116063\ttotal: 1.41s\tremaining: 5.28s\n",
            "211:\tlearn: 27.8010109\ttotal: 1.42s\tremaining: 5.27s\n",
            "212:\tlearn: 27.7596224\ttotal: 1.43s\tremaining: 5.27s\n",
            "213:\tlearn: 27.7370119\ttotal: 1.43s\tremaining: 5.26s\n",
            "214:\tlearn: 27.7260782\ttotal: 1.44s\tremaining: 5.25s\n",
            "215:\tlearn: 27.6985272\ttotal: 1.45s\tremaining: 5.25s\n",
            "216:\tlearn: 27.6640186\ttotal: 1.45s\tremaining: 5.24s\n",
            "217:\tlearn: 27.6478277\ttotal: 1.46s\tremaining: 5.23s\n",
            "218:\tlearn: 27.6211370\ttotal: 1.47s\tremaining: 5.23s\n",
            "219:\tlearn: 27.5847595\ttotal: 1.47s\tremaining: 5.22s\n",
            "220:\tlearn: 27.5743255\ttotal: 1.48s\tremaining: 5.21s\n",
            "221:\tlearn: 27.5628797\ttotal: 1.49s\tremaining: 5.21s\n",
            "222:\tlearn: 27.5527412\ttotal: 1.49s\tremaining: 5.2s\n",
            "223:\tlearn: 27.5351979\ttotal: 1.5s\tremaining: 5.19s\n",
            "224:\tlearn: 27.5252130\ttotal: 1.51s\tremaining: 5.19s\n",
            "225:\tlearn: 27.4912216\ttotal: 1.51s\tremaining: 5.18s\n",
            "226:\tlearn: 27.4810102\ttotal: 1.52s\tremaining: 5.18s\n",
            "227:\tlearn: 27.4713250\ttotal: 1.53s\tremaining: 5.17s\n",
            "228:\tlearn: 27.4543277\ttotal: 1.53s\tremaining: 5.16s\n",
            "229:\tlearn: 27.4311479\ttotal: 1.54s\tremaining: 5.15s\n",
            "230:\tlearn: 27.4215462\ttotal: 1.54s\tremaining: 5.14s\n",
            "231:\tlearn: 27.3970088\ttotal: 1.55s\tremaining: 5.14s\n",
            "232:\tlearn: 27.3875656\ttotal: 1.56s\tremaining: 5.13s\n",
            "233:\tlearn: 27.3781610\ttotal: 1.56s\tremaining: 5.12s\n",
            "234:\tlearn: 27.3589896\ttotal: 1.57s\tremaining: 5.12s\n",
            "235:\tlearn: 27.3324403\ttotal: 1.58s\tremaining: 5.11s\n",
            "236:\tlearn: 27.2989865\ttotal: 1.58s\tremaining: 5.1s\n",
            "237:\tlearn: 27.2739907\ttotal: 1.59s\tremaining: 5.1s\n",
            "238:\tlearn: 27.2591919\ttotal: 1.6s\tremaining: 5.09s\n",
            "239:\tlearn: 27.2499230\ttotal: 1.6s\tremaining: 5.08s\n",
            "240:\tlearn: 27.2403187\ttotal: 1.61s\tremaining: 5.07s\n",
            "241:\tlearn: 27.2033477\ttotal: 1.62s\tremaining: 5.07s\n",
            "242:\tlearn: 27.1889180\ttotal: 1.62s\tremaining: 5.06s\n",
            "243:\tlearn: 27.1626563\ttotal: 1.63s\tremaining: 5.05s\n",
            "244:\tlearn: 27.1276212\ttotal: 1.64s\tremaining: 5.04s\n",
            "245:\tlearn: 27.1181655\ttotal: 1.64s\tremaining: 5.04s\n",
            "246:\tlearn: 27.0944706\ttotal: 1.65s\tremaining: 5.03s\n",
            "247:\tlearn: 27.0716992\ttotal: 1.66s\tremaining: 5.02s\n",
            "248:\tlearn: 27.0444270\ttotal: 1.66s\tremaining: 5.01s\n",
            "249:\tlearn: 27.0353573\ttotal: 1.67s\tremaining: 5.01s\n",
            "250:\tlearn: 27.0087494\ttotal: 1.68s\tremaining: 5s\n",
            "251:\tlearn: 26.9858743\ttotal: 1.68s\tremaining: 5s\n",
            "252:\tlearn: 26.9775819\ttotal: 1.69s\tremaining: 4.99s\n",
            "253:\tlearn: 26.9621935\ttotal: 1.7s\tremaining: 4.98s\n",
            "254:\tlearn: 26.9532990\ttotal: 1.7s\tremaining: 4.98s\n",
            "255:\tlearn: 26.9349436\ttotal: 1.71s\tremaining: 4.97s\n",
            "256:\tlearn: 26.9261379\ttotal: 1.72s\tremaining: 4.97s\n",
            "257:\tlearn: 26.8977376\ttotal: 1.73s\tremaining: 4.96s\n",
            "258:\tlearn: 26.8849457\ttotal: 1.73s\tremaining: 4.95s\n",
            "259:\tlearn: 26.8762264\ttotal: 1.74s\tremaining: 4.95s\n",
            "260:\tlearn: 26.8537052\ttotal: 1.74s\tremaining: 4.94s\n",
            "261:\tlearn: 26.8310271\ttotal: 1.75s\tremaining: 4.93s\n",
            "262:\tlearn: 26.8230404\ttotal: 1.76s\tremaining: 4.92s\n",
            "263:\tlearn: 26.8151828\ttotal: 1.76s\tremaining: 4.92s\n",
            "264:\tlearn: 26.7966602\ttotal: 1.77s\tremaining: 4.91s\n",
            "265:\tlearn: 26.7819028\ttotal: 1.78s\tremaining: 4.91s\n",
            "266:\tlearn: 26.7734183\ttotal: 1.78s\tremaining: 4.9s\n",
            "267:\tlearn: 26.7516981\ttotal: 1.79s\tremaining: 4.9s\n",
            "268:\tlearn: 26.7389988\ttotal: 1.8s\tremaining: 4.89s\n",
            "269:\tlearn: 26.7177772\ttotal: 1.81s\tremaining: 4.88s\n",
            "270:\tlearn: 26.7093726\ttotal: 1.81s\tremaining: 4.88s\n",
            "271:\tlearn: 26.7004178\ttotal: 1.82s\tremaining: 4.87s\n",
            "272:\tlearn: 26.6921857\ttotal: 1.83s\tremaining: 4.87s\n",
            "273:\tlearn: 26.6834606\ttotal: 1.83s\tremaining: 4.86s\n",
            "274:\tlearn: 26.6680879\ttotal: 1.84s\tremaining: 4.85s\n",
            "275:\tlearn: 26.6384777\ttotal: 1.85s\tremaining: 4.85s\n",
            "276:\tlearn: 26.6298868\ttotal: 1.85s\tremaining: 4.84s\n",
            "277:\tlearn: 26.6214459\ttotal: 1.86s\tremaining: 4.83s\n",
            "278:\tlearn: 26.6131481\ttotal: 1.87s\tremaining: 4.83s\n",
            "279:\tlearn: 26.5857151\ttotal: 1.88s\tremaining: 4.82s\n",
            "280:\tlearn: 26.5775308\ttotal: 1.88s\tremaining: 4.82s\n",
            "281:\tlearn: 26.5694881\ttotal: 1.89s\tremaining: 4.81s\n",
            "282:\tlearn: 26.5615712\ttotal: 1.9s\tremaining: 4.8s\n",
            "283:\tlearn: 26.5490906\ttotal: 1.93s\tremaining: 4.86s\n",
            "284:\tlearn: 26.5420255\ttotal: 1.94s\tremaining: 4.86s\n",
            "285:\tlearn: 26.5128035\ttotal: 1.95s\tremaining: 4.86s\n",
            "286:\tlearn: 26.4904170\ttotal: 1.95s\tremaining: 4.85s\n",
            "287:\tlearn: 26.4826631\ttotal: 1.96s\tremaining: 4.84s\n",
            "288:\tlearn: 26.4701121\ttotal: 1.97s\tremaining: 4.83s\n",
            "289:\tlearn: 26.4620948\ttotal: 1.97s\tremaining: 4.83s\n",
            "290:\tlearn: 26.4314350\ttotal: 1.98s\tremaining: 4.82s\n",
            "291:\tlearn: 26.4115587\ttotal: 1.99s\tremaining: 4.82s\n",
            "292:\tlearn: 26.3966907\ttotal: 1.99s\tremaining: 4.81s\n",
            "293:\tlearn: 26.3762144\ttotal: 2s\tremaining: 4.8s\n",
            "294:\tlearn: 26.3687164\ttotal: 2.01s\tremaining: 4.8s\n",
            "295:\tlearn: 26.3618758\ttotal: 2.01s\tremaining: 4.79s\n",
            "296:\tlearn: 26.3487180\ttotal: 2.02s\tremaining: 4.79s\n",
            "297:\tlearn: 26.3309265\ttotal: 2.03s\tremaining: 4.78s\n",
            "298:\tlearn: 26.3235732\ttotal: 2.03s\tremaining: 4.77s\n",
            "299:\tlearn: 26.3158429\ttotal: 2.04s\tremaining: 4.76s\n",
            "300:\tlearn: 26.2928420\ttotal: 2.05s\tremaining: 4.76s\n",
            "301:\tlearn: 26.2779657\ttotal: 2.06s\tremaining: 4.75s\n",
            "302:\tlearn: 26.2650417\ttotal: 2.06s\tremaining: 4.74s\n",
            "303:\tlearn: 26.2532095\ttotal: 2.07s\tremaining: 4.74s\n",
            "304:\tlearn: 26.2313303\ttotal: 2.08s\tremaining: 4.73s\n",
            "305:\tlearn: 26.2240817\ttotal: 2.08s\tremaining: 4.72s\n",
            "306:\tlearn: 26.2136422\ttotal: 2.09s\tremaining: 4.72s\n",
            "307:\tlearn: 26.2048708\ttotal: 2.1s\tremaining: 4.71s\n",
            "308:\tlearn: 26.1983059\ttotal: 2.1s\tremaining: 4.7s\n",
            "309:\tlearn: 26.1848302\ttotal: 2.11s\tremaining: 4.7s\n",
            "310:\tlearn: 26.1579240\ttotal: 2.12s\tremaining: 4.69s\n",
            "311:\tlearn: 26.1508752\ttotal: 2.13s\tremaining: 4.69s\n",
            "312:\tlearn: 26.1321333\ttotal: 2.13s\tremaining: 4.68s\n",
            "313:\tlearn: 26.1076708\ttotal: 2.14s\tremaining: 4.67s\n",
            "314:\tlearn: 26.1007090\ttotal: 2.15s\tremaining: 4.67s\n",
            "315:\tlearn: 26.0883117\ttotal: 2.15s\tremaining: 4.66s\n",
            "316:\tlearn: 26.0743592\ttotal: 2.16s\tremaining: 4.65s\n",
            "317:\tlearn: 26.0648051\ttotal: 2.17s\tremaining: 4.64s\n",
            "318:\tlearn: 26.0350636\ttotal: 2.17s\tremaining: 4.64s\n",
            "319:\tlearn: 26.0281564\ttotal: 2.18s\tremaining: 4.63s\n",
            "320:\tlearn: 26.0009435\ttotal: 2.19s\tremaining: 4.63s\n",
            "321:\tlearn: 25.9890083\ttotal: 2.2s\tremaining: 4.63s\n",
            "322:\tlearn: 25.9821730\ttotal: 2.2s\tremaining: 4.62s\n",
            "323:\tlearn: 25.9737951\ttotal: 2.21s\tremaining: 4.61s\n",
            "324:\tlearn: 25.9670851\ttotal: 2.22s\tremaining: 4.61s\n",
            "325:\tlearn: 25.9433957\ttotal: 2.23s\tremaining: 4.6s\n",
            "326:\tlearn: 25.9335922\ttotal: 2.23s\tremaining: 4.59s\n",
            "327:\tlearn: 25.9125477\ttotal: 2.24s\tremaining: 4.58s\n",
            "328:\tlearn: 25.8927255\ttotal: 2.25s\tremaining: 4.58s\n",
            "329:\tlearn: 25.8814321\ttotal: 2.25s\tremaining: 4.57s\n",
            "330:\tlearn: 25.8710217\ttotal: 2.26s\tremaining: 4.56s\n",
            "331:\tlearn: 25.8643834\ttotal: 2.26s\tremaining: 4.56s\n",
            "332:\tlearn: 25.8375219\ttotal: 2.27s\tremaining: 4.55s\n",
            "333:\tlearn: 25.8256759\ttotal: 2.28s\tremaining: 4.54s\n",
            "334:\tlearn: 25.8022930\ttotal: 2.29s\tremaining: 4.54s\n",
            "335:\tlearn: 25.7761333\ttotal: 2.29s\tremaining: 4.53s\n",
            "336:\tlearn: 25.7586038\ttotal: 2.3s\tremaining: 4.53s\n",
            "337:\tlearn: 25.7408903\ttotal: 2.31s\tremaining: 4.52s\n",
            "338:\tlearn: 25.7080189\ttotal: 2.31s\tremaining: 4.51s\n",
            "339:\tlearn: 25.7013992\ttotal: 2.32s\tremaining: 4.5s\n",
            "340:\tlearn: 25.6796846\ttotal: 2.33s\tremaining: 4.5s\n",
            "341:\tlearn: 25.6677782\ttotal: 2.33s\tremaining: 4.49s\n",
            "342:\tlearn: 25.6430332\ttotal: 2.34s\tremaining: 4.49s\n",
            "343:\tlearn: 25.6261261\ttotal: 2.35s\tremaining: 4.48s\n",
            "344:\tlearn: 25.6161447\ttotal: 2.36s\tremaining: 4.48s\n",
            "345:\tlearn: 25.6064924\ttotal: 2.36s\tremaining: 4.47s\n",
            "346:\tlearn: 25.5882474\ttotal: 2.37s\tremaining: 4.46s\n",
            "347:\tlearn: 25.5817092\ttotal: 2.38s\tremaining: 4.46s\n",
            "348:\tlearn: 25.5568007\ttotal: 2.39s\tremaining: 4.45s\n",
            "349:\tlearn: 25.5497314\ttotal: 2.39s\tremaining: 4.44s\n",
            "350:\tlearn: 25.5433295\ttotal: 2.4s\tremaining: 4.44s\n",
            "351:\tlearn: 25.5370002\ttotal: 2.41s\tremaining: 4.43s\n",
            "352:\tlearn: 25.5165802\ttotal: 2.41s\tremaining: 4.42s\n",
            "353:\tlearn: 25.5097433\ttotal: 2.42s\tremaining: 4.42s\n",
            "354:\tlearn: 25.5030300\ttotal: 2.43s\tremaining: 4.41s\n",
            "355:\tlearn: 25.4964322\ttotal: 2.43s\tremaining: 4.4s\n",
            "356:\tlearn: 25.4899282\ttotal: 2.44s\tremaining: 4.39s\n",
            "357:\tlearn: 25.4792051\ttotal: 2.45s\tremaining: 4.39s\n",
            "358:\tlearn: 25.4728126\ttotal: 2.45s\tremaining: 4.38s\n",
            "359:\tlearn: 25.4665270\ttotal: 2.46s\tremaining: 4.37s\n",
            "360:\tlearn: 25.4432040\ttotal: 2.47s\tremaining: 4.37s\n",
            "361:\tlearn: 25.4369967\ttotal: 2.47s\tremaining: 4.36s\n",
            "362:\tlearn: 25.4217104\ttotal: 2.48s\tremaining: 4.35s\n",
            "363:\tlearn: 25.3975900\ttotal: 2.49s\tremaining: 4.35s\n",
            "364:\tlearn: 25.3890170\ttotal: 2.49s\tremaining: 4.34s\n",
            "365:\tlearn: 25.3655400\ttotal: 2.5s\tremaining: 4.33s\n",
            "366:\tlearn: 25.3594198\ttotal: 2.51s\tremaining: 4.33s\n",
            "367:\tlearn: 25.3491354\ttotal: 2.51s\tremaining: 4.32s\n",
            "368:\tlearn: 25.3372574\ttotal: 2.52s\tremaining: 4.31s\n",
            "369:\tlearn: 25.3298780\ttotal: 2.53s\tremaining: 4.31s\n",
            "370:\tlearn: 25.3183293\ttotal: 2.54s\tremaining: 4.3s\n",
            "371:\tlearn: 25.3123104\ttotal: 2.54s\tremaining: 4.3s\n",
            "372:\tlearn: 25.2961953\ttotal: 2.55s\tremaining: 4.29s\n",
            "373:\tlearn: 25.2767052\ttotal: 2.56s\tremaining: 4.28s\n",
            "374:\tlearn: 25.2541606\ttotal: 2.57s\tremaining: 4.28s\n",
            "375:\tlearn: 25.2389209\ttotal: 2.58s\tremaining: 4.28s\n",
            "376:\tlearn: 25.2166678\ttotal: 2.58s\tremaining: 4.27s\n",
            "377:\tlearn: 25.1988271\ttotal: 2.59s\tremaining: 4.26s\n",
            "378:\tlearn: 25.1848409\ttotal: 2.6s\tremaining: 4.26s\n",
            "379:\tlearn: 25.1744857\ttotal: 2.6s\tremaining: 4.25s\n",
            "380:\tlearn: 25.1672364\ttotal: 2.61s\tremaining: 4.24s\n",
            "381:\tlearn: 25.1564952\ttotal: 2.62s\tremaining: 4.24s\n",
            "382:\tlearn: 25.1507112\ttotal: 2.62s\tremaining: 4.23s\n",
            "383:\tlearn: 25.1411514\ttotal: 2.63s\tremaining: 4.22s\n",
            "384:\tlearn: 25.1191759\ttotal: 2.64s\tremaining: 4.21s\n",
            "385:\tlearn: 25.1134372\ttotal: 2.65s\tremaining: 4.21s\n",
            "386:\tlearn: 25.1077548\ttotal: 2.65s\tremaining: 4.2s\n",
            "387:\tlearn: 25.0982747\ttotal: 2.66s\tremaining: 4.19s\n",
            "388:\tlearn: 25.0786874\ttotal: 2.67s\tremaining: 4.19s\n",
            "389:\tlearn: 25.0619898\ttotal: 2.67s\tremaining: 4.18s\n",
            "390:\tlearn: 25.0525876\ttotal: 2.68s\tremaining: 4.17s\n",
            "391:\tlearn: 25.0265749\ttotal: 2.69s\tremaining: 4.17s\n",
            "392:\tlearn: 25.0010744\ttotal: 2.69s\tremaining: 4.16s\n",
            "393:\tlearn: 24.9826148\ttotal: 2.7s\tremaining: 4.15s\n",
            "394:\tlearn: 24.9769505\ttotal: 2.71s\tremaining: 4.14s\n",
            "395:\tlearn: 24.9687921\ttotal: 2.71s\tremaining: 4.14s\n",
            "396:\tlearn: 24.9507458\ttotal: 2.72s\tremaining: 4.13s\n",
            "397:\tlearn: 24.9415664\ttotal: 2.73s\tremaining: 4.12s\n",
            "398:\tlearn: 24.9238235\ttotal: 2.73s\tremaining: 4.12s\n",
            "399:\tlearn: 24.9181955\ttotal: 2.74s\tremaining: 4.11s\n",
            "400:\tlearn: 24.9126227\ttotal: 2.75s\tremaining: 4.1s\n",
            "401:\tlearn: 24.8955770\ttotal: 2.75s\tremaining: 4.09s\n",
            "402:\tlearn: 24.8718355\ttotal: 2.76s\tremaining: 4.09s\n",
            "403:\tlearn: 24.8663075\ttotal: 2.77s\tremaining: 4.08s\n",
            "404:\tlearn: 24.8517657\ttotal: 2.77s\tremaining: 4.07s\n",
            "405:\tlearn: 24.8354759\ttotal: 2.78s\tremaining: 4.07s\n",
            "406:\tlearn: 24.8299898\ttotal: 2.79s\tremaining: 4.06s\n",
            "407:\tlearn: 24.8108465\ttotal: 2.79s\tremaining: 4.05s\n",
            "408:\tlearn: 24.7918525\ttotal: 2.8s\tremaining: 4.05s\n",
            "409:\tlearn: 24.7769961\ttotal: 2.81s\tremaining: 4.04s\n",
            "410:\tlearn: 24.7624246\ttotal: 2.81s\tremaining: 4.03s\n",
            "411:\tlearn: 24.7553455\ttotal: 2.82s\tremaining: 4.03s\n",
            "412:\tlearn: 24.7430328\ttotal: 2.83s\tremaining: 4.02s\n",
            "413:\tlearn: 24.7279170\ttotal: 2.83s\tremaining: 4.01s\n",
            "414:\tlearn: 24.7224648\ttotal: 2.84s\tremaining: 4s\n",
            "415:\tlearn: 24.7125938\ttotal: 2.85s\tremaining: 4s\n",
            "416:\tlearn: 24.7072042\ttotal: 2.85s\tremaining: 3.99s\n",
            "417:\tlearn: 24.6836728\ttotal: 2.86s\tremaining: 3.98s\n",
            "418:\tlearn: 24.6702981\ttotal: 2.87s\tremaining: 3.98s\n",
            "419:\tlearn: 24.6555931\ttotal: 2.87s\tremaining: 3.97s\n",
            "420:\tlearn: 24.6413202\ttotal: 2.88s\tremaining: 3.96s\n",
            "421:\tlearn: 24.6298942\ttotal: 2.89s\tremaining: 3.95s\n",
            "422:\tlearn: 24.6245287\ttotal: 2.89s\tremaining: 3.94s\n",
            "423:\tlearn: 24.6110441\ttotal: 2.9s\tremaining: 3.94s\n",
            "424:\tlearn: 24.6041107\ttotal: 2.9s\tremaining: 3.93s\n",
            "425:\tlearn: 24.5932666\ttotal: 2.91s\tremaining: 3.92s\n",
            "426:\tlearn: 24.5836463\ttotal: 2.92s\tremaining: 3.92s\n",
            "427:\tlearn: 24.5731032\ttotal: 2.92s\tremaining: 3.91s\n",
            "428:\tlearn: 24.5677722\ttotal: 2.93s\tremaining: 3.9s\n",
            "429:\tlearn: 24.5494039\ttotal: 2.94s\tremaining: 3.89s\n",
            "430:\tlearn: 24.5315523\ttotal: 2.94s\tremaining: 3.89s\n",
            "431:\tlearn: 24.5191541\ttotal: 2.95s\tremaining: 3.88s\n",
            "432:\tlearn: 24.5070131\ttotal: 2.96s\tremaining: 3.87s\n",
            "433:\tlearn: 24.5017313\ttotal: 2.97s\tremaining: 3.87s\n",
            "434:\tlearn: 24.4935004\ttotal: 2.97s\tremaining: 3.86s\n",
            "435:\tlearn: 24.4882481\ttotal: 2.98s\tremaining: 3.85s\n",
            "436:\tlearn: 24.4787119\ttotal: 2.99s\tremaining: 3.85s\n",
            "437:\tlearn: 24.4735069\ttotal: 2.99s\tremaining: 3.84s\n",
            "438:\tlearn: 24.4588599\ttotal: 3s\tremaining: 3.83s\n",
            "439:\tlearn: 24.4452682\ttotal: 3.01s\tremaining: 3.83s\n",
            "440:\tlearn: 24.4401143\ttotal: 3.01s\tremaining: 3.82s\n",
            "441:\tlearn: 24.4278295\ttotal: 3.02s\tremaining: 3.81s\n",
            "442:\tlearn: 24.4196116\ttotal: 3.03s\tremaining: 3.81s\n",
            "443:\tlearn: 24.4029463\ttotal: 3.03s\tremaining: 3.8s\n",
            "444:\tlearn: 24.3978138\ttotal: 3.04s\tremaining: 3.79s\n",
            "445:\tlearn: 24.3833842\ttotal: 3.05s\tremaining: 3.79s\n",
            "446:\tlearn: 24.3757984\ttotal: 3.05s\tremaining: 3.78s\n",
            "447:\tlearn: 24.3600751\ttotal: 3.06s\tremaining: 3.77s\n",
            "448:\tlearn: 24.3549788\ttotal: 3.07s\tremaining: 3.76s\n",
            "449:\tlearn: 24.3502212\ttotal: 3.07s\tremaining: 3.76s\n",
            "450:\tlearn: 24.3452074\ttotal: 3.08s\tremaining: 3.75s\n",
            "451:\tlearn: 24.3264919\ttotal: 3.09s\tremaining: 3.74s\n",
            "452:\tlearn: 24.3215270\ttotal: 3.09s\tremaining: 3.73s\n",
            "453:\tlearn: 24.2983714\ttotal: 3.1s\tremaining: 3.73s\n",
            "454:\tlearn: 24.2856791\ttotal: 3.11s\tremaining: 3.72s\n",
            "455:\tlearn: 24.2736279\ttotal: 3.11s\tremaining: 3.71s\n",
            "456:\tlearn: 24.2661327\ttotal: 3.12s\tremaining: 3.71s\n",
            "457:\tlearn: 24.2612228\ttotal: 3.13s\tremaining: 3.7s\n",
            "458:\tlearn: 24.2563341\ttotal: 3.13s\tremaining: 3.69s\n",
            "459:\tlearn: 24.2514913\ttotal: 3.14s\tremaining: 3.69s\n",
            "460:\tlearn: 24.2404204\ttotal: 3.15s\tremaining: 3.68s\n",
            "461:\tlearn: 24.2254028\ttotal: 3.15s\tremaining: 3.67s\n",
            "462:\tlearn: 24.2140158\ttotal: 3.16s\tremaining: 3.67s\n",
            "463:\tlearn: 24.2072019\ttotal: 3.17s\tremaining: 3.66s\n",
            "464:\tlearn: 24.1988619\ttotal: 3.18s\tremaining: 3.65s\n",
            "465:\tlearn: 24.1940687\ttotal: 3.18s\tremaining: 3.65s\n",
            "466:\tlearn: 24.1778235\ttotal: 3.19s\tremaining: 3.64s\n",
            "467:\tlearn: 24.1730506\ttotal: 3.2s\tremaining: 3.64s\n",
            "468:\tlearn: 24.1683261\ttotal: 3.21s\tremaining: 3.63s\n",
            "469:\tlearn: 24.1574467\ttotal: 3.21s\tremaining: 3.62s\n",
            "470:\tlearn: 24.1417995\ttotal: 3.22s\tremaining: 3.62s\n",
            "471:\tlearn: 24.1347049\ttotal: 3.23s\tremaining: 3.61s\n",
            "472:\tlearn: 24.1182372\ttotal: 3.23s\tremaining: 3.6s\n",
            "473:\tlearn: 24.1014807\ttotal: 3.24s\tremaining: 3.59s\n",
            "474:\tlearn: 24.0968003\ttotal: 3.25s\tremaining: 3.59s\n",
            "475:\tlearn: 24.0802471\ttotal: 3.25s\tremaining: 3.58s\n",
            "476:\tlearn: 24.0550875\ttotal: 3.26s\tremaining: 3.57s\n",
            "477:\tlearn: 24.0442187\ttotal: 3.27s\tremaining: 3.57s\n",
            "478:\tlearn: 24.0380065\ttotal: 3.27s\tremaining: 3.56s\n",
            "479:\tlearn: 24.0333242\ttotal: 3.28s\tremaining: 3.55s\n",
            "480:\tlearn: 24.0286928\ttotal: 3.29s\tremaining: 3.54s\n",
            "481:\tlearn: 24.0122262\ttotal: 3.29s\tremaining: 3.54s\n",
            "482:\tlearn: 24.0076429\ttotal: 3.3s\tremaining: 3.53s\n",
            "483:\tlearn: 24.0001356\ttotal: 3.31s\tremaining: 3.52s\n",
            "484:\tlearn: 23.9927757\ttotal: 3.31s\tremaining: 3.52s\n",
            "485:\tlearn: 23.9882171\ttotal: 3.32s\tremaining: 3.51s\n",
            "486:\tlearn: 23.9645054\ttotal: 3.33s\tremaining: 3.5s\n",
            "487:\tlearn: 23.9599875\ttotal: 3.33s\tremaining: 3.5s\n",
            "488:\tlearn: 23.9512714\ttotal: 3.34s\tremaining: 3.49s\n",
            "489:\tlearn: 23.9451431\ttotal: 3.35s\tremaining: 3.48s\n",
            "490:\tlearn: 23.9290796\ttotal: 3.35s\tremaining: 3.48s\n",
            "491:\tlearn: 23.9194899\ttotal: 3.36s\tremaining: 3.47s\n",
            "492:\tlearn: 23.9150125\ttotal: 3.37s\tremaining: 3.46s\n",
            "493:\tlearn: 23.9105697\ttotal: 3.37s\tremaining: 3.45s\n",
            "494:\tlearn: 23.8936049\ttotal: 3.38s\tremaining: 3.45s\n",
            "495:\tlearn: 23.8894163\ttotal: 3.39s\tremaining: 3.44s\n",
            "496:\tlearn: 23.8800820\ttotal: 3.39s\tremaining: 3.43s\n",
            "497:\tlearn: 23.8616856\ttotal: 3.4s\tremaining: 3.43s\n",
            "498:\tlearn: 23.8524508\ttotal: 3.41s\tremaining: 3.42s\n",
            "499:\tlearn: 23.8460615\ttotal: 3.41s\tremaining: 3.41s\n",
            "500:\tlearn: 23.8369872\ttotal: 3.42s\tremaining: 3.41s\n",
            "501:\tlearn: 23.8240878\ttotal: 3.43s\tremaining: 3.4s\n",
            "502:\tlearn: 23.8196938\ttotal: 3.43s\tremaining: 3.39s\n",
            "503:\tlearn: 23.8111708\ttotal: 3.44s\tremaining: 3.38s\n",
            "504:\tlearn: 23.8025547\ttotal: 3.45s\tremaining: 3.38s\n",
            "505:\tlearn: 23.7981945\ttotal: 3.45s\tremaining: 3.37s\n",
            "506:\tlearn: 23.7858949\ttotal: 3.46s\tremaining: 3.36s\n",
            "507:\tlearn: 23.7815669\ttotal: 3.47s\tremaining: 3.36s\n",
            "508:\tlearn: 23.7734366\ttotal: 3.47s\tremaining: 3.35s\n",
            "509:\tlearn: 23.7643286\ttotal: 3.48s\tremaining: 3.34s\n",
            "510:\tlearn: 23.7571396\ttotal: 3.48s\tremaining: 3.33s\n",
            "511:\tlearn: 23.7528481\ttotal: 3.49s\tremaining: 3.33s\n",
            "512:\tlearn: 23.7485753\ttotal: 3.5s\tremaining: 3.32s\n",
            "513:\tlearn: 23.7263814\ttotal: 3.5s\tremaining: 3.31s\n",
            "514:\tlearn: 23.7187558\ttotal: 3.51s\tremaining: 3.31s\n",
            "515:\tlearn: 23.7104104\ttotal: 3.52s\tremaining: 3.3s\n",
            "516:\tlearn: 23.6922552\ttotal: 3.52s\tremaining: 3.29s\n",
            "517:\tlearn: 23.6810949\ttotal: 3.53s\tremaining: 3.29s\n",
            "518:\tlearn: 23.6768470\ttotal: 3.54s\tremaining: 3.28s\n",
            "519:\tlearn: 23.6652112\ttotal: 3.54s\tremaining: 3.27s\n",
            "520:\tlearn: 23.6609959\ttotal: 3.55s\tremaining: 3.27s\n",
            "521:\tlearn: 23.6494622\ttotal: 3.56s\tremaining: 3.26s\n",
            "522:\tlearn: 23.6431860\ttotal: 3.56s\tremaining: 3.25s\n",
            "523:\tlearn: 23.6389961\ttotal: 3.57s\tremaining: 3.25s\n",
            "524:\tlearn: 23.6226573\ttotal: 3.58s\tremaining: 3.24s\n",
            "525:\tlearn: 23.6155476\ttotal: 3.59s\tremaining: 3.23s\n",
            "526:\tlearn: 23.5998482\ttotal: 3.6s\tremaining: 3.23s\n",
            "527:\tlearn: 23.5917053\ttotal: 3.6s\tremaining: 3.22s\n",
            "528:\tlearn: 23.5820095\ttotal: 3.61s\tremaining: 3.21s\n",
            "529:\tlearn: 23.5778425\ttotal: 3.62s\tremaining: 3.21s\n",
            "530:\tlearn: 23.5655661\ttotal: 3.62s\tremaining: 3.2s\n",
            "531:\tlearn: 23.5614302\ttotal: 3.63s\tremaining: 3.19s\n",
            "532:\tlearn: 23.5406168\ttotal: 3.63s\tremaining: 3.19s\n",
            "533:\tlearn: 23.5332563\ttotal: 3.64s\tremaining: 3.18s\n",
            "534:\tlearn: 23.5170213\ttotal: 3.65s\tremaining: 3.17s\n",
            "535:\tlearn: 23.5090714\ttotal: 3.66s\tremaining: 3.17s\n",
            "536:\tlearn: 23.4976472\ttotal: 3.66s\tremaining: 3.16s\n",
            "537:\tlearn: 23.4935339\ttotal: 3.67s\tremaining: 3.15s\n",
            "538:\tlearn: 23.4878418\ttotal: 3.68s\tremaining: 3.14s\n",
            "539:\tlearn: 23.4778515\ttotal: 3.68s\tremaining: 3.14s\n",
            "540:\tlearn: 23.4720745\ttotal: 3.69s\tremaining: 3.13s\n",
            "541:\tlearn: 23.4679822\ttotal: 3.7s\tremaining: 3.12s\n",
            "542:\tlearn: 23.4639275\ttotal: 3.7s\tremaining: 3.12s\n",
            "543:\tlearn: 23.4535301\ttotal: 3.71s\tremaining: 3.11s\n",
            "544:\tlearn: 23.4495152\ttotal: 3.72s\tremaining: 3.1s\n",
            "545:\tlearn: 23.4439135\ttotal: 3.72s\tremaining: 3.1s\n",
            "546:\tlearn: 23.4399232\ttotal: 3.73s\tremaining: 3.09s\n",
            "547:\tlearn: 23.4359586\ttotal: 3.74s\tremaining: 3.08s\n",
            "548:\tlearn: 23.4269641\ttotal: 3.74s\tremaining: 3.08s\n",
            "549:\tlearn: 23.4177955\ttotal: 3.75s\tremaining: 3.07s\n",
            "550:\tlearn: 23.4138621\ttotal: 3.76s\tremaining: 3.06s\n",
            "551:\tlearn: 23.4009765\ttotal: 3.77s\tremaining: 3.06s\n",
            "552:\tlearn: 23.3932601\ttotal: 3.79s\tremaining: 3.06s\n",
            "553:\tlearn: 23.3790747\ttotal: 3.79s\tremaining: 3.06s\n",
            "554:\tlearn: 23.3721081\ttotal: 3.8s\tremaining: 3.05s\n",
            "555:\tlearn: 23.3645936\ttotal: 3.81s\tremaining: 3.04s\n",
            "556:\tlearn: 23.3581421\ttotal: 3.82s\tremaining: 3.04s\n",
            "557:\tlearn: 23.3463904\ttotal: 3.83s\tremaining: 3.03s\n",
            "558:\tlearn: 23.3421002\ttotal: 3.83s\tremaining: 3.02s\n",
            "559:\tlearn: 23.3253529\ttotal: 3.84s\tremaining: 3.02s\n",
            "560:\tlearn: 23.3153567\ttotal: 3.85s\tremaining: 3.01s\n",
            "561:\tlearn: 23.3116101\ttotal: 3.85s\tremaining: 3s\n",
            "562:\tlearn: 23.3073908\ttotal: 3.86s\tremaining: 3s\n",
            "563:\tlearn: 23.3032368\ttotal: 3.87s\tremaining: 2.99s\n",
            "564:\tlearn: 23.2994224\ttotal: 3.87s\tremaining: 2.98s\n",
            "565:\tlearn: 23.2953552\ttotal: 3.88s\tremaining: 2.97s\n",
            "566:\tlearn: 23.2913417\ttotal: 3.89s\tremaining: 2.97s\n",
            "567:\tlearn: 23.2873878\ttotal: 3.89s\tremaining: 2.96s\n",
            "568:\tlearn: 23.2805499\ttotal: 3.9s\tremaining: 2.95s\n",
            "569:\tlearn: 23.2766597\ttotal: 3.91s\tremaining: 2.95s\n",
            "570:\tlearn: 23.2728171\ttotal: 3.91s\tremaining: 2.94s\n",
            "571:\tlearn: 23.2564749\ttotal: 3.92s\tremaining: 2.93s\n",
            "572:\tlearn: 23.2508163\ttotal: 3.93s\tremaining: 2.93s\n",
            "573:\tlearn: 23.2434171\ttotal: 3.93s\tremaining: 2.92s\n",
            "574:\tlearn: 23.2345568\ttotal: 3.94s\tremaining: 2.91s\n",
            "575:\tlearn: 23.2307477\ttotal: 3.95s\tremaining: 2.91s\n",
            "576:\tlearn: 23.2269987\ttotal: 3.96s\tremaining: 2.9s\n",
            "577:\tlearn: 23.2203016\ttotal: 3.96s\tremaining: 2.89s\n",
            "578:\tlearn: 23.2081109\ttotal: 3.97s\tremaining: 2.89s\n",
            "579:\tlearn: 23.1956253\ttotal: 3.98s\tremaining: 2.88s\n",
            "580:\tlearn: 23.1776859\ttotal: 3.98s\tremaining: 2.87s\n",
            "581:\tlearn: 23.1720280\ttotal: 3.99s\tremaining: 2.87s\n",
            "582:\tlearn: 23.1619582\ttotal: 4s\tremaining: 2.86s\n",
            "583:\tlearn: 23.1463885\ttotal: 4.01s\tremaining: 2.85s\n",
            "584:\tlearn: 23.1390056\ttotal: 4.01s\tremaining: 2.85s\n",
            "585:\tlearn: 23.1323633\ttotal: 4.02s\tremaining: 2.84s\n",
            "586:\tlearn: 23.1286452\ttotal: 4.03s\tremaining: 2.83s\n",
            "587:\tlearn: 23.1227433\ttotal: 4.04s\tremaining: 2.83s\n",
            "588:\tlearn: 23.1070150\ttotal: 4.04s\tremaining: 2.82s\n",
            "589:\tlearn: 23.0893150\ttotal: 4.05s\tremaining: 2.81s\n",
            "590:\tlearn: 23.0856391\ttotal: 4.06s\tremaining: 2.81s\n",
            "591:\tlearn: 23.0784512\ttotal: 4.07s\tremaining: 2.8s\n",
            "592:\tlearn: 23.0691331\ttotal: 4.07s\tremaining: 2.79s\n",
            "593:\tlearn: 23.0643568\ttotal: 4.08s\tremaining: 2.79s\n",
            "594:\tlearn: 23.0544611\ttotal: 4.08s\tremaining: 2.78s\n",
            "595:\tlearn: 23.0485592\ttotal: 4.09s\tremaining: 2.77s\n",
            "596:\tlearn: 23.0376095\ttotal: 4.1s\tremaining: 2.77s\n",
            "597:\tlearn: 23.0304341\ttotal: 4.11s\tremaining: 2.76s\n",
            "598:\tlearn: 23.0268095\ttotal: 4.11s\tremaining: 2.75s\n",
            "599:\tlearn: 23.0232118\ttotal: 4.12s\tremaining: 2.75s\n",
            "600:\tlearn: 23.0196446\ttotal: 4.12s\tremaining: 2.74s\n",
            "601:\tlearn: 23.0130377\ttotal: 4.13s\tremaining: 2.73s\n",
            "602:\tlearn: 22.9962106\ttotal: 4.14s\tremaining: 2.72s\n",
            "603:\tlearn: 22.9856590\ttotal: 4.14s\tremaining: 2.72s\n",
            "604:\tlearn: 22.9821105\ttotal: 4.15s\tremaining: 2.71s\n",
            "605:\tlearn: 22.9749418\ttotal: 4.16s\tremaining: 2.7s\n",
            "606:\tlearn: 22.9693192\ttotal: 4.17s\tremaining: 2.7s\n",
            "607:\tlearn: 22.9529881\ttotal: 4.17s\tremaining: 2.69s\n",
            "608:\tlearn: 22.9494645\ttotal: 4.18s\tremaining: 2.68s\n",
            "609:\tlearn: 22.9362174\ttotal: 4.19s\tremaining: 2.68s\n",
            "610:\tlearn: 22.9291892\ttotal: 4.19s\tremaining: 2.67s\n",
            "611:\tlearn: 22.9256873\ttotal: 4.2s\tremaining: 2.66s\n",
            "612:\tlearn: 22.9143995\ttotal: 4.21s\tremaining: 2.65s\n",
            "613:\tlearn: 22.9009384\ttotal: 4.21s\tremaining: 2.65s\n",
            "614:\tlearn: 22.8966947\ttotal: 4.22s\tremaining: 2.64s\n",
            "615:\tlearn: 22.8898131\ttotal: 4.23s\tremaining: 2.63s\n",
            "616:\tlearn: 22.8860357\ttotal: 4.23s\tremaining: 2.63s\n",
            "617:\tlearn: 22.8825766\ttotal: 4.24s\tremaining: 2.62s\n",
            "618:\tlearn: 22.8757782\ttotal: 4.25s\tremaining: 2.61s\n",
            "619:\tlearn: 22.8596314\ttotal: 4.25s\tremaining: 2.61s\n",
            "620:\tlearn: 22.8484852\ttotal: 4.26s\tremaining: 2.6s\n",
            "621:\tlearn: 22.8416864\ttotal: 4.27s\tremaining: 2.59s\n",
            "622:\tlearn: 22.8261214\ttotal: 4.27s\tremaining: 2.58s\n",
            "623:\tlearn: 22.8226841\ttotal: 4.28s\tremaining: 2.58s\n",
            "624:\tlearn: 22.8171777\ttotal: 4.29s\tremaining: 2.57s\n",
            "625:\tlearn: 22.8037777\ttotal: 4.29s\tremaining: 2.56s\n",
            "626:\tlearn: 22.8000512\ttotal: 4.3s\tremaining: 2.56s\n",
            "627:\tlearn: 22.7857969\ttotal: 4.3s\tremaining: 2.55s\n",
            "628:\tlearn: 22.7765353\ttotal: 4.31s\tremaining: 2.54s\n",
            "629:\tlearn: 22.7731295\ttotal: 4.32s\tremaining: 2.54s\n",
            "630:\tlearn: 22.7685880\ttotal: 4.33s\tremaining: 2.53s\n",
            "631:\tlearn: 22.7619514\ttotal: 4.33s\tremaining: 2.52s\n",
            "632:\tlearn: 22.7507543\ttotal: 4.34s\tremaining: 2.52s\n",
            "633:\tlearn: 22.7473859\ttotal: 4.34s\tremaining: 2.51s\n",
            "634:\tlearn: 22.7420224\ttotal: 4.35s\tremaining: 2.5s\n",
            "635:\tlearn: 22.7355642\ttotal: 4.36s\tremaining: 2.49s\n",
            "636:\tlearn: 22.7223946\ttotal: 4.36s\tremaining: 2.49s\n",
            "637:\tlearn: 22.7174161\ttotal: 4.37s\tremaining: 2.48s\n",
            "638:\tlearn: 22.7038083\ttotal: 4.38s\tremaining: 2.47s\n",
            "639:\tlearn: 22.6975167\ttotal: 4.39s\tremaining: 2.47s\n",
            "640:\tlearn: 22.6863417\ttotal: 4.39s\tremaining: 2.46s\n",
            "641:\tlearn: 22.6819275\ttotal: 4.4s\tremaining: 2.46s\n",
            "642:\tlearn: 22.6692597\ttotal: 4.41s\tremaining: 2.45s\n",
            "643:\tlearn: 22.6644160\ttotal: 4.42s\tremaining: 2.44s\n",
            "644:\tlearn: 22.6581786\ttotal: 4.43s\tremaining: 2.44s\n",
            "645:\tlearn: 22.6493012\ttotal: 4.43s\tremaining: 2.43s\n",
            "646:\tlearn: 22.6361525\ttotal: 4.44s\tremaining: 2.42s\n",
            "647:\tlearn: 22.6305591\ttotal: 4.45s\tremaining: 2.42s\n",
            "648:\tlearn: 22.6243970\ttotal: 4.46s\tremaining: 2.41s\n",
            "649:\tlearn: 22.6166964\ttotal: 4.46s\tremaining: 2.4s\n",
            "650:\tlearn: 22.6063847\ttotal: 4.47s\tremaining: 2.4s\n",
            "651:\tlearn: 22.6030298\ttotal: 4.48s\tremaining: 2.39s\n",
            "652:\tlearn: 22.5847835\ttotal: 4.48s\tremaining: 2.38s\n",
            "653:\tlearn: 22.5814517\ttotal: 4.49s\tremaining: 2.37s\n",
            "654:\tlearn: 22.5730651\ttotal: 4.5s\tremaining: 2.37s\n",
            "655:\tlearn: 22.5674000\ttotal: 4.5s\tremaining: 2.36s\n",
            "656:\tlearn: 22.5619898\ttotal: 4.51s\tremaining: 2.35s\n",
            "657:\tlearn: 22.5543099\ttotal: 4.51s\tremaining: 2.35s\n",
            "658:\tlearn: 22.5510024\ttotal: 4.52s\tremaining: 2.34s\n",
            "659:\tlearn: 22.5349662\ttotal: 4.53s\tremaining: 2.33s\n",
            "660:\tlearn: 22.5241777\ttotal: 4.53s\tremaining: 2.33s\n",
            "661:\tlearn: 22.5195861\ttotal: 4.54s\tremaining: 2.32s\n",
            "662:\tlearn: 22.5163068\ttotal: 4.55s\tremaining: 2.31s\n",
            "663:\tlearn: 22.5116377\ttotal: 4.55s\tremaining: 2.3s\n",
            "664:\tlearn: 22.5085261\ttotal: 4.56s\tremaining: 2.3s\n",
            "665:\tlearn: 22.5042454\ttotal: 4.57s\tremaining: 2.29s\n",
            "666:\tlearn: 22.5010096\ttotal: 4.57s\tremaining: 2.28s\n",
            "667:\tlearn: 22.4977940\ttotal: 4.58s\tremaining: 2.27s\n",
            "668:\tlearn: 22.4947594\ttotal: 4.58s\tremaining: 2.27s\n",
            "669:\tlearn: 22.4843065\ttotal: 4.59s\tremaining: 2.26s\n",
            "670:\tlearn: 22.4811299\ttotal: 4.6s\tremaining: 2.25s\n",
            "671:\tlearn: 22.4756763\ttotal: 4.6s\tremaining: 2.25s\n",
            "672:\tlearn: 22.4725229\ttotal: 4.61s\tremaining: 2.24s\n",
            "673:\tlearn: 22.4695472\ttotal: 4.62s\tremaining: 2.23s\n",
            "674:\tlearn: 22.4651755\ttotal: 4.62s\tremaining: 2.23s\n",
            "675:\tlearn: 22.4480962\ttotal: 4.63s\tremaining: 2.22s\n",
            "676:\tlearn: 22.4326259\ttotal: 4.64s\tremaining: 2.21s\n",
            "677:\tlearn: 22.4274424\ttotal: 4.64s\tremaining: 2.21s\n",
            "678:\tlearn: 22.4243180\ttotal: 4.65s\tremaining: 2.2s\n",
            "679:\tlearn: 22.4162264\ttotal: 4.66s\tremaining: 2.19s\n",
            "680:\tlearn: 22.4084633\ttotal: 4.66s\tremaining: 2.18s\n",
            "681:\tlearn: 22.3915321\ttotal: 4.67s\tremaining: 2.18s\n",
            "682:\tlearn: 22.3774834\ttotal: 4.68s\tremaining: 2.17s\n",
            "683:\tlearn: 22.3733116\ttotal: 4.68s\tremaining: 2.16s\n",
            "684:\tlearn: 22.3688391\ttotal: 4.69s\tremaining: 2.16s\n",
            "685:\tlearn: 22.3550910\ttotal: 4.7s\tremaining: 2.15s\n",
            "686:\tlearn: 22.3519789\ttotal: 4.7s\tremaining: 2.14s\n",
            "687:\tlearn: 22.3426344\ttotal: 4.71s\tremaining: 2.14s\n",
            "688:\tlearn: 22.3395429\ttotal: 4.72s\tremaining: 2.13s\n",
            "689:\tlearn: 22.3335608\ttotal: 4.72s\tremaining: 2.12s\n",
            "690:\tlearn: 22.3228328\ttotal: 4.73s\tremaining: 2.12s\n",
            "691:\tlearn: 22.3110635\ttotal: 4.74s\tremaining: 2.11s\n",
            "692:\tlearn: 22.3057272\ttotal: 4.74s\tremaining: 2.1s\n",
            "693:\tlearn: 22.2900180\ttotal: 4.75s\tremaining: 2.09s\n",
            "694:\tlearn: 22.2851509\ttotal: 4.76s\tremaining: 2.09s\n",
            "695:\tlearn: 22.2810656\ttotal: 4.76s\tremaining: 2.08s\n",
            "696:\tlearn: 22.2695867\ttotal: 4.77s\tremaining: 2.07s\n",
            "697:\tlearn: 22.2629711\ttotal: 4.78s\tremaining: 2.07s\n",
            "698:\tlearn: 22.2598982\ttotal: 4.78s\tremaining: 2.06s\n",
            "699:\tlearn: 22.2568445\ttotal: 4.79s\tremaining: 2.05s\n",
            "700:\tlearn: 22.2538093\ttotal: 4.79s\tremaining: 2.04s\n",
            "701:\tlearn: 22.2507861\ttotal: 4.8s\tremaining: 2.04s\n",
            "702:\tlearn: 22.2477907\ttotal: 4.81s\tremaining: 2.03s\n",
            "703:\tlearn: 22.2423580\ttotal: 4.81s\tremaining: 2.02s\n",
            "704:\tlearn: 22.2372481\ttotal: 4.82s\tremaining: 2.02s\n",
            "705:\tlearn: 22.2208739\ttotal: 4.83s\tremaining: 2.01s\n",
            "706:\tlearn: 22.2174356\ttotal: 4.83s\tremaining: 2s\n",
            "707:\tlearn: 22.2135578\ttotal: 4.84s\tremaining: 2s\n",
            "708:\tlearn: 22.2060563\ttotal: 4.85s\tremaining: 1.99s\n",
            "709:\tlearn: 22.1971066\ttotal: 4.85s\tremaining: 1.98s\n",
            "710:\tlearn: 22.1893747\ttotal: 4.86s\tremaining: 1.98s\n",
            "711:\tlearn: 22.1863986\ttotal: 4.87s\tremaining: 1.97s\n",
            "712:\tlearn: 22.1834384\ttotal: 4.87s\tremaining: 1.96s\n",
            "713:\tlearn: 22.1804939\ttotal: 4.88s\tremaining: 1.95s\n",
            "714:\tlearn: 22.1775750\ttotal: 4.89s\tremaining: 1.95s\n",
            "715:\tlearn: 22.1710931\ttotal: 4.89s\tremaining: 1.94s\n",
            "716:\tlearn: 22.1681920\ttotal: 4.9s\tremaining: 1.93s\n",
            "717:\tlearn: 22.1654339\ttotal: 4.91s\tremaining: 1.93s\n",
            "718:\tlearn: 22.1608668\ttotal: 4.91s\tremaining: 1.92s\n",
            "719:\tlearn: 22.1579905\ttotal: 4.92s\tremaining: 1.91s\n",
            "720:\tlearn: 22.1455252\ttotal: 4.92s\tremaining: 1.91s\n",
            "721:\tlearn: 22.1426693\ttotal: 4.93s\tremaining: 1.9s\n",
            "722:\tlearn: 22.1377950\ttotal: 4.94s\tremaining: 1.89s\n",
            "723:\tlearn: 22.1350852\ttotal: 4.94s\tremaining: 1.88s\n",
            "724:\tlearn: 22.1320008\ttotal: 4.95s\tremaining: 1.88s\n",
            "725:\tlearn: 22.1258540\ttotal: 4.96s\tremaining: 1.87s\n",
            "726:\tlearn: 22.1200129\ttotal: 4.96s\tremaining: 1.86s\n",
            "727:\tlearn: 22.1164196\ttotal: 4.97s\tremaining: 1.86s\n",
            "728:\tlearn: 22.1136048\ttotal: 4.98s\tremaining: 1.85s\n",
            "729:\tlearn: 22.1069020\ttotal: 4.98s\tremaining: 1.84s\n",
            "730:\tlearn: 22.0972662\ttotal: 4.99s\tremaining: 1.84s\n",
            "731:\tlearn: 22.0922069\ttotal: 5s\tremaining: 1.83s\n",
            "732:\tlearn: 22.0894074\ttotal: 5s\tremaining: 1.82s\n",
            "733:\tlearn: 22.0847892\ttotal: 5.01s\tremaining: 1.82s\n",
            "734:\tlearn: 22.0809729\ttotal: 5.02s\tremaining: 1.81s\n",
            "735:\tlearn: 22.0777173\ttotal: 5.03s\tremaining: 1.8s\n",
            "736:\tlearn: 22.0749399\ttotal: 5.03s\tremaining: 1.8s\n",
            "737:\tlearn: 22.0657840\ttotal: 5.04s\tremaining: 1.79s\n",
            "738:\tlearn: 22.0585128\ttotal: 5.05s\tremaining: 1.78s\n",
            "739:\tlearn: 22.0500650\ttotal: 5.05s\tremaining: 1.78s\n",
            "740:\tlearn: 22.0430156\ttotal: 5.06s\tremaining: 1.77s\n",
            "741:\tlearn: 22.0402526\ttotal: 5.07s\tremaining: 1.76s\n",
            "742:\tlearn: 22.0365534\ttotal: 5.08s\tremaining: 1.75s\n",
            "743:\tlearn: 22.0338130\ttotal: 5.08s\tremaining: 1.75s\n",
            "744:\tlearn: 22.0178126\ttotal: 5.09s\tremaining: 1.74s\n",
            "745:\tlearn: 22.0100561\ttotal: 5.1s\tremaining: 1.74s\n",
            "746:\tlearn: 22.0073249\ttotal: 5.1s\tremaining: 1.73s\n",
            "747:\tlearn: 21.9859753\ttotal: 5.11s\tremaining: 1.72s\n",
            "748:\tlearn: 21.9832568\ttotal: 5.12s\tremaining: 1.72s\n",
            "749:\tlearn: 21.9753421\ttotal: 5.13s\tremaining: 1.71s\n",
            "750:\tlearn: 21.9726424\ttotal: 5.13s\tremaining: 1.7s\n",
            "751:\tlearn: 21.9613287\ttotal: 5.14s\tremaining: 1.7s\n",
            "752:\tlearn: 21.9571031\ttotal: 5.15s\tremaining: 1.69s\n",
            "753:\tlearn: 21.9544209\ttotal: 5.16s\tremaining: 1.68s\n",
            "754:\tlearn: 21.9479926\ttotal: 5.17s\tremaining: 1.68s\n",
            "755:\tlearn: 21.9431582\ttotal: 5.17s\tremaining: 1.67s\n",
            "756:\tlearn: 21.9389620\ttotal: 5.18s\tremaining: 1.66s\n",
            "757:\tlearn: 21.9362852\ttotal: 5.19s\tremaining: 1.66s\n",
            "758:\tlearn: 21.9270778\ttotal: 5.19s\tremaining: 1.65s\n",
            "759:\tlearn: 21.9244230\ttotal: 5.2s\tremaining: 1.64s\n",
            "760:\tlearn: 21.9188894\ttotal: 5.21s\tremaining: 1.64s\n",
            "761:\tlearn: 21.9162551\ttotal: 5.21s\tremaining: 1.63s\n",
            "762:\tlearn: 21.9059195\ttotal: 5.22s\tremaining: 1.62s\n",
            "763:\tlearn: 21.8909552\ttotal: 5.23s\tremaining: 1.61s\n",
            "764:\tlearn: 21.8833621\ttotal: 5.23s\tremaining: 1.61s\n",
            "765:\tlearn: 21.8779520\ttotal: 5.24s\tremaining: 1.6s\n",
            "766:\tlearn: 21.8650337\ttotal: 5.25s\tremaining: 1.59s\n",
            "767:\tlearn: 21.8598092\ttotal: 5.25s\tremaining: 1.59s\n",
            "768:\tlearn: 21.8562904\ttotal: 5.26s\tremaining: 1.58s\n",
            "769:\tlearn: 21.8467599\ttotal: 5.27s\tremaining: 1.57s\n",
            "770:\tlearn: 21.8418868\ttotal: 5.28s\tremaining: 1.57s\n",
            "771:\tlearn: 21.8331013\ttotal: 5.28s\tremaining: 1.56s\n",
            "772:\tlearn: 21.8295557\ttotal: 5.29s\tremaining: 1.55s\n",
            "773:\tlearn: 21.8269252\ttotal: 5.3s\tremaining: 1.55s\n",
            "774:\tlearn: 21.8243049\ttotal: 5.3s\tremaining: 1.54s\n",
            "775:\tlearn: 21.8176247\ttotal: 5.31s\tremaining: 1.53s\n",
            "776:\tlearn: 21.8122776\ttotal: 5.32s\tremaining: 1.53s\n",
            "777:\tlearn: 21.8096713\ttotal: 5.33s\tremaining: 1.52s\n",
            "778:\tlearn: 21.8070834\ttotal: 5.33s\tremaining: 1.51s\n",
            "779:\tlearn: 21.8020742\ttotal: 5.34s\tremaining: 1.51s\n",
            "780:\tlearn: 21.7995026\ttotal: 5.35s\tremaining: 1.5s\n",
            "781:\tlearn: 21.7932996\ttotal: 5.35s\tremaining: 1.49s\n",
            "782:\tlearn: 21.7905075\ttotal: 5.36s\tremaining: 1.49s\n",
            "783:\tlearn: 21.7869361\ttotal: 5.37s\tremaining: 1.48s\n",
            "784:\tlearn: 21.7843848\ttotal: 5.37s\tremaining: 1.47s\n",
            "785:\tlearn: 21.7796350\ttotal: 5.38s\tremaining: 1.47s\n",
            "786:\tlearn: 21.7756325\ttotal: 5.39s\tremaining: 1.46s\n",
            "787:\tlearn: 21.7693443\ttotal: 5.39s\tremaining: 1.45s\n",
            "788:\tlearn: 21.7589237\ttotal: 5.4s\tremaining: 1.44s\n",
            "789:\tlearn: 21.7446489\ttotal: 5.41s\tremaining: 1.44s\n",
            "790:\tlearn: 21.7334698\ttotal: 5.42s\tremaining: 1.43s\n",
            "791:\tlearn: 21.7309246\ttotal: 5.42s\tremaining: 1.42s\n",
            "792:\tlearn: 21.7283966\ttotal: 5.43s\tremaining: 1.42s\n",
            "793:\tlearn: 21.7217878\ttotal: 5.43s\tremaining: 1.41s\n",
            "794:\tlearn: 21.7107367\ttotal: 5.44s\tremaining: 1.4s\n",
            "795:\tlearn: 21.7058677\ttotal: 5.45s\tremaining: 1.4s\n",
            "796:\tlearn: 21.7007651\ttotal: 5.46s\tremaining: 1.39s\n",
            "797:\tlearn: 21.6961387\ttotal: 5.46s\tremaining: 1.38s\n",
            "798:\tlearn: 21.6891914\ttotal: 5.47s\tremaining: 1.38s\n",
            "799:\tlearn: 21.6731007\ttotal: 5.48s\tremaining: 1.37s\n",
            "800:\tlearn: 21.6705905\ttotal: 5.48s\tremaining: 1.36s\n",
            "801:\tlearn: 21.6656014\ttotal: 5.49s\tremaining: 1.35s\n",
            "802:\tlearn: 21.6615839\ttotal: 5.5s\tremaining: 1.35s\n",
            "803:\tlearn: 21.6590972\ttotal: 5.5s\tremaining: 1.34s\n",
            "804:\tlearn: 21.6518430\ttotal: 5.51s\tremaining: 1.33s\n",
            "805:\tlearn: 21.6479273\ttotal: 5.52s\tremaining: 1.33s\n",
            "806:\tlearn: 21.6426457\ttotal: 5.53s\tremaining: 1.32s\n",
            "807:\tlearn: 21.6339472\ttotal: 5.53s\tremaining: 1.31s\n",
            "808:\tlearn: 21.6314664\ttotal: 5.54s\tremaining: 1.31s\n",
            "809:\tlearn: 21.6244736\ttotal: 5.54s\tremaining: 1.3s\n",
            "810:\tlearn: 21.6220304\ttotal: 5.55s\tremaining: 1.29s\n",
            "811:\tlearn: 21.6107790\ttotal: 5.56s\tremaining: 1.29s\n",
            "812:\tlearn: 21.6057006\ttotal: 5.57s\tremaining: 1.28s\n",
            "813:\tlearn: 21.6011806\ttotal: 5.57s\tremaining: 1.27s\n",
            "814:\tlearn: 21.5936144\ttotal: 5.58s\tremaining: 1.27s\n",
            "815:\tlearn: 21.5897830\ttotal: 5.59s\tremaining: 1.26s\n",
            "816:\tlearn: 21.5873288\ttotal: 5.6s\tremaining: 1.25s\n",
            "817:\tlearn: 21.5693617\ttotal: 5.6s\tremaining: 1.25s\n",
            "818:\tlearn: 21.5667028\ttotal: 5.61s\tremaining: 1.24s\n",
            "819:\tlearn: 21.5609702\ttotal: 5.62s\tremaining: 1.23s\n",
            "820:\tlearn: 21.5548415\ttotal: 5.63s\tremaining: 1.23s\n",
            "821:\tlearn: 21.5524077\ttotal: 5.63s\tremaining: 1.22s\n",
            "822:\tlearn: 21.5488551\ttotal: 5.64s\tremaining: 1.21s\n",
            "823:\tlearn: 21.5428402\ttotal: 5.65s\tremaining: 1.21s\n",
            "824:\tlearn: 21.5404202\ttotal: 5.65s\tremaining: 1.2s\n",
            "825:\tlearn: 21.5378229\ttotal: 5.66s\tremaining: 1.19s\n",
            "826:\tlearn: 21.5352563\ttotal: 5.67s\tremaining: 1.19s\n",
            "827:\tlearn: 21.5327219\ttotal: 5.67s\tremaining: 1.18s\n",
            "828:\tlearn: 21.5302186\ttotal: 5.68s\tremaining: 1.17s\n",
            "829:\tlearn: 21.5138354\ttotal: 5.69s\tremaining: 1.17s\n",
            "830:\tlearn: 21.5113602\ttotal: 5.7s\tremaining: 1.16s\n",
            "831:\tlearn: 21.5089226\ttotal: 5.71s\tremaining: 1.15s\n",
            "832:\tlearn: 21.5065157\ttotal: 5.72s\tremaining: 1.15s\n",
            "833:\tlearn: 21.5041333\ttotal: 5.73s\tremaining: 1.14s\n",
            "834:\tlearn: 21.5017762\ttotal: 5.73s\tremaining: 1.13s\n",
            "835:\tlearn: 21.4829298\ttotal: 5.74s\tremaining: 1.13s\n",
            "836:\tlearn: 21.4805965\ttotal: 5.75s\tremaining: 1.12s\n",
            "837:\tlearn: 21.4747907\ttotal: 5.75s\tremaining: 1.11s\n",
            "838:\tlearn: 21.4724817\ttotal: 5.76s\tremaining: 1.1s\n",
            "839:\tlearn: 21.4658729\ttotal: 5.77s\tremaining: 1.1s\n",
            "840:\tlearn: 21.4635965\ttotal: 5.78s\tremaining: 1.09s\n",
            "841:\tlearn: 21.4576821\ttotal: 5.78s\tremaining: 1.08s\n",
            "842:\tlearn: 21.4554284\ttotal: 5.79s\tremaining: 1.08s\n",
            "843:\tlearn: 21.4445342\ttotal: 5.8s\tremaining: 1.07s\n",
            "844:\tlearn: 21.4398549\ttotal: 5.8s\tremaining: 1.06s\n",
            "845:\tlearn: 21.4358540\ttotal: 5.81s\tremaining: 1.06s\n",
            "846:\tlearn: 21.4321356\ttotal: 5.82s\tremaining: 1.05s\n",
            "847:\tlearn: 21.4233565\ttotal: 5.83s\tremaining: 1.04s\n",
            "848:\tlearn: 21.4188053\ttotal: 5.83s\tremaining: 1.04s\n",
            "849:\tlearn: 21.4104165\ttotal: 5.84s\tremaining: 1.03s\n",
            "850:\tlearn: 21.4015950\ttotal: 5.85s\tremaining: 1.02s\n",
            "851:\tlearn: 21.3982421\ttotal: 5.85s\tremaining: 1.02s\n",
            "852:\tlearn: 21.3959600\ttotal: 5.86s\tremaining: 1.01s\n",
            "853:\tlearn: 21.3909284\ttotal: 5.87s\tremaining: 1s\n",
            "854:\tlearn: 21.3800126\ttotal: 5.88s\tremaining: 997ms\n",
            "855:\tlearn: 21.3752790\ttotal: 5.88s\tremaining: 990ms\n",
            "856:\tlearn: 21.3687743\ttotal: 5.89s\tremaining: 983ms\n",
            "857:\tlearn: 21.3553158\ttotal: 5.9s\tremaining: 976ms\n",
            "858:\tlearn: 21.3503682\ttotal: 5.91s\tremaining: 970ms\n",
            "859:\tlearn: 21.3480892\ttotal: 5.91s\tremaining: 963ms\n",
            "860:\tlearn: 21.3458574\ttotal: 5.92s\tremaining: 956ms\n",
            "861:\tlearn: 21.3436109\ttotal: 5.93s\tremaining: 949ms\n",
            "862:\tlearn: 21.3323500\ttotal: 5.93s\tremaining: 942ms\n",
            "863:\tlearn: 21.3298079\ttotal: 5.94s\tremaining: 935ms\n",
            "864:\tlearn: 21.3258678\ttotal: 5.95s\tremaining: 928ms\n",
            "865:\tlearn: 21.3139233\ttotal: 5.95s\tremaining: 921ms\n",
            "866:\tlearn: 21.3060477\ttotal: 5.96s\tremaining: 915ms\n",
            "867:\tlearn: 21.2887223\ttotal: 5.97s\tremaining: 908ms\n",
            "868:\tlearn: 21.2862905\ttotal: 5.97s\tremaining: 901ms\n",
            "869:\tlearn: 21.2840717\ttotal: 5.98s\tremaining: 894ms\n",
            "870:\tlearn: 21.2777315\ttotal: 5.99s\tremaining: 887ms\n",
            "871:\tlearn: 21.2711751\ttotal: 6s\tremaining: 880ms\n",
            "872:\tlearn: 21.2658775\ttotal: 6s\tremaining: 873ms\n",
            "873:\tlearn: 21.2618588\ttotal: 6.01s\tremaining: 866ms\n",
            "874:\tlearn: 21.2551565\ttotal: 6.01s\tremaining: 859ms\n",
            "875:\tlearn: 21.2509639\ttotal: 6.02s\tremaining: 853ms\n",
            "876:\tlearn: 21.2487334\ttotal: 6.03s\tremaining: 846ms\n",
            "877:\tlearn: 21.2465140\ttotal: 6.04s\tremaining: 839ms\n",
            "878:\tlearn: 21.2378791\ttotal: 6.04s\tremaining: 832ms\n",
            "879:\tlearn: 21.2323418\ttotal: 6.05s\tremaining: 825ms\n",
            "880:\tlearn: 21.2278492\ttotal: 6.06s\tremaining: 818ms\n",
            "881:\tlearn: 21.2254976\ttotal: 6.06s\tremaining: 811ms\n",
            "882:\tlearn: 21.2226067\ttotal: 6.07s\tremaining: 804ms\n",
            "883:\tlearn: 21.2202170\ttotal: 6.08s\tremaining: 797ms\n",
            "884:\tlearn: 21.2163103\ttotal: 6.08s\tremaining: 791ms\n",
            "885:\tlearn: 21.2080934\ttotal: 6.09s\tremaining: 784ms\n",
            "886:\tlearn: 21.2031308\ttotal: 6.1s\tremaining: 777ms\n",
            "887:\tlearn: 21.2007698\ttotal: 6.1s\tremaining: 770ms\n",
            "888:\tlearn: 21.1952925\ttotal: 6.11s\tremaining: 763ms\n",
            "889:\tlearn: 21.1913162\ttotal: 6.12s\tremaining: 756ms\n",
            "890:\tlearn: 21.1891356\ttotal: 6.13s\tremaining: 749ms\n",
            "891:\tlearn: 21.1868116\ttotal: 6.13s\tremaining: 743ms\n",
            "892:\tlearn: 21.1839355\ttotal: 6.14s\tremaining: 736ms\n",
            "893:\tlearn: 21.1806090\ttotal: 6.15s\tremaining: 729ms\n",
            "894:\tlearn: 21.1784472\ttotal: 6.15s\tremaining: 722ms\n",
            "895:\tlearn: 21.1761657\ttotal: 6.16s\tremaining: 715ms\n",
            "896:\tlearn: 21.1739149\ttotal: 6.17s\tremaining: 708ms\n",
            "897:\tlearn: 21.1716895\ttotal: 6.17s\tremaining: 701ms\n",
            "898:\tlearn: 21.1694879\ttotal: 6.18s\tremaining: 694ms\n",
            "899:\tlearn: 21.1673123\ttotal: 6.19s\tremaining: 687ms\n",
            "900:\tlearn: 21.1651598\ttotal: 6.19s\tremaining: 680ms\n",
            "901:\tlearn: 21.1630340\ttotal: 6.2s\tremaining: 674ms\n",
            "902:\tlearn: 21.1609363\ttotal: 6.21s\tremaining: 667ms\n",
            "903:\tlearn: 21.1439343\ttotal: 6.21s\tremaining: 660ms\n",
            "904:\tlearn: 21.1402849\ttotal: 6.22s\tremaining: 653ms\n",
            "905:\tlearn: 21.1382055\ttotal: 6.22s\tremaining: 646ms\n",
            "906:\tlearn: 21.1361451\ttotal: 6.23s\tremaining: 639ms\n",
            "907:\tlearn: 21.1273947\ttotal: 6.24s\tremaining: 632ms\n",
            "908:\tlearn: 21.1202076\ttotal: 6.25s\tremaining: 625ms\n",
            "909:\tlearn: 21.1181687\ttotal: 6.25s\tremaining: 618ms\n",
            "910:\tlearn: 21.1161486\ttotal: 6.26s\tremaining: 611ms\n",
            "911:\tlearn: 21.1072335\ttotal: 6.26s\tremaining: 604ms\n",
            "912:\tlearn: 21.1052342\ttotal: 6.27s\tremaining: 598ms\n",
            "913:\tlearn: 21.0998132\ttotal: 6.28s\tremaining: 591ms\n",
            "914:\tlearn: 21.0956264\ttotal: 6.28s\tremaining: 584ms\n",
            "915:\tlearn: 21.0927807\ttotal: 6.29s\tremaining: 577ms\n",
            "916:\tlearn: 21.0890182\ttotal: 6.3s\tremaining: 570ms\n",
            "917:\tlearn: 21.0858689\ttotal: 6.3s\tremaining: 563ms\n",
            "918:\tlearn: 21.0807833\ttotal: 6.31s\tremaining: 556ms\n",
            "919:\tlearn: 21.0717619\ttotal: 6.32s\tremaining: 549ms\n",
            "920:\tlearn: 21.0628249\ttotal: 6.33s\tremaining: 543ms\n",
            "921:\tlearn: 21.0532659\ttotal: 6.33s\tremaining: 536ms\n",
            "922:\tlearn: 21.0505767\ttotal: 6.34s\tremaining: 529ms\n",
            "923:\tlearn: 21.0485292\ttotal: 6.34s\tremaining: 522ms\n",
            "924:\tlearn: 21.0373609\ttotal: 6.35s\tremaining: 515ms\n",
            "925:\tlearn: 21.0314595\ttotal: 6.36s\tremaining: 508ms\n",
            "926:\tlearn: 21.0267188\ttotal: 6.36s\tremaining: 501ms\n",
            "927:\tlearn: 21.0223739\ttotal: 6.37s\tremaining: 494ms\n",
            "928:\tlearn: 21.0059730\ttotal: 6.38s\tremaining: 487ms\n",
            "929:\tlearn: 21.0039534\ttotal: 6.38s\tremaining: 481ms\n",
            "930:\tlearn: 20.9995631\ttotal: 6.39s\tremaining: 474ms\n",
            "931:\tlearn: 20.9944667\ttotal: 6.4s\tremaining: 467ms\n",
            "932:\tlearn: 20.9896400\ttotal: 6.4s\tremaining: 460ms\n",
            "933:\tlearn: 20.9732870\ttotal: 6.41s\tremaining: 453ms\n",
            "934:\tlearn: 20.9654646\ttotal: 6.42s\tremaining: 446ms\n",
            "935:\tlearn: 20.9568736\ttotal: 6.42s\tremaining: 439ms\n",
            "936:\tlearn: 20.9532076\ttotal: 6.43s\tremaining: 432ms\n",
            "937:\tlearn: 20.9375689\ttotal: 6.43s\tremaining: 425ms\n",
            "938:\tlearn: 20.9219532\ttotal: 6.44s\tremaining: 418ms\n",
            "939:\tlearn: 20.9163294\ttotal: 6.45s\tremaining: 412ms\n",
            "940:\tlearn: 20.9059785\ttotal: 6.45s\tremaining: 405ms\n",
            "941:\tlearn: 20.9014627\ttotal: 6.46s\tremaining: 398ms\n",
            "942:\tlearn: 20.8844677\ttotal: 6.47s\tremaining: 391ms\n",
            "943:\tlearn: 20.8824240\ttotal: 6.47s\tremaining: 384ms\n",
            "944:\tlearn: 20.8729390\ttotal: 6.48s\tremaining: 377ms\n",
            "945:\tlearn: 20.8638758\ttotal: 6.49s\tremaining: 370ms\n",
            "946:\tlearn: 20.8613791\ttotal: 6.49s\tremaining: 363ms\n",
            "947:\tlearn: 20.8463824\ttotal: 6.5s\tremaining: 356ms\n",
            "948:\tlearn: 20.8443439\ttotal: 6.5s\tremaining: 350ms\n",
            "949:\tlearn: 20.8423128\ttotal: 6.51s\tremaining: 343ms\n",
            "950:\tlearn: 20.8320814\ttotal: 6.52s\tremaining: 336ms\n",
            "951:\tlearn: 20.8286739\ttotal: 6.53s\tremaining: 329ms\n",
            "952:\tlearn: 20.8213184\ttotal: 6.53s\tremaining: 322ms\n",
            "953:\tlearn: 20.8144477\ttotal: 6.54s\tremaining: 315ms\n",
            "954:\tlearn: 20.8102251\ttotal: 6.54s\tremaining: 308ms\n",
            "955:\tlearn: 20.8066930\ttotal: 6.55s\tremaining: 302ms\n",
            "956:\tlearn: 20.8042921\ttotal: 6.56s\tremaining: 295ms\n",
            "957:\tlearn: 20.7912345\ttotal: 6.56s\tremaining: 288ms\n",
            "958:\tlearn: 20.7836879\ttotal: 6.57s\tremaining: 281ms\n",
            "959:\tlearn: 20.7816614\ttotal: 6.58s\tremaining: 274ms\n",
            "960:\tlearn: 20.7732650\ttotal: 6.58s\tremaining: 267ms\n",
            "961:\tlearn: 20.7633147\ttotal: 6.59s\tremaining: 260ms\n",
            "962:\tlearn: 20.7593472\ttotal: 6.6s\tremaining: 253ms\n",
            "963:\tlearn: 20.7496799\ttotal: 6.6s\tremaining: 247ms\n",
            "964:\tlearn: 20.7393618\ttotal: 6.61s\tremaining: 240ms\n",
            "965:\tlearn: 20.7299676\ttotal: 6.62s\tremaining: 233ms\n",
            "966:\tlearn: 20.7171549\ttotal: 6.62s\tremaining: 226ms\n",
            "967:\tlearn: 20.7139943\ttotal: 6.63s\tremaining: 219ms\n",
            "968:\tlearn: 20.7119727\ttotal: 6.63s\tremaining: 212ms\n",
            "969:\tlearn: 20.7026579\ttotal: 6.64s\tremaining: 205ms\n",
            "970:\tlearn: 20.6986026\ttotal: 6.65s\tremaining: 199ms\n",
            "971:\tlearn: 20.6895501\ttotal: 6.65s\tremaining: 192ms\n",
            "972:\tlearn: 20.6858703\ttotal: 6.66s\tremaining: 185ms\n",
            "973:\tlearn: 20.6838614\ttotal: 6.67s\tremaining: 178ms\n",
            "974:\tlearn: 20.6818603\ttotal: 6.67s\tremaining: 171ms\n",
            "975:\tlearn: 20.6779849\ttotal: 6.68s\tremaining: 164ms\n",
            "976:\tlearn: 20.6702429\ttotal: 6.69s\tremaining: 157ms\n",
            "977:\tlearn: 20.6661650\ttotal: 6.69s\tremaining: 151ms\n",
            "978:\tlearn: 20.6573813\ttotal: 6.7s\tremaining: 144ms\n",
            "979:\tlearn: 20.6553870\ttotal: 6.71s\tremaining: 137ms\n",
            "980:\tlearn: 20.6534005\ttotal: 6.71s\tremaining: 130ms\n",
            "981:\tlearn: 20.6433501\ttotal: 6.72s\tremaining: 123ms\n",
            "982:\tlearn: 20.6292683\ttotal: 6.72s\tremaining: 116ms\n",
            "983:\tlearn: 20.6273374\ttotal: 6.73s\tremaining: 109ms\n",
            "984:\tlearn: 20.6249287\ttotal: 6.74s\tremaining: 103ms\n",
            "985:\tlearn: 20.6169875\ttotal: 6.75s\tremaining: 95.8ms\n",
            "986:\tlearn: 20.6150194\ttotal: 6.75s\tremaining: 88.9ms\n",
            "987:\tlearn: 20.6015438\ttotal: 6.76s\tremaining: 82.1ms\n",
            "988:\tlearn: 20.5995245\ttotal: 6.76s\tremaining: 75.2ms\n",
            "989:\tlearn: 20.5975762\ttotal: 6.77s\tremaining: 68.4ms\n",
            "990:\tlearn: 20.5956241\ttotal: 6.78s\tremaining: 61.6ms\n",
            "991:\tlearn: 20.5920557\ttotal: 6.78s\tremaining: 54.7ms\n",
            "992:\tlearn: 20.5883127\ttotal: 6.79s\tremaining: 47.9ms\n",
            "993:\tlearn: 20.5863676\ttotal: 6.8s\tremaining: 41ms\n",
            "994:\tlearn: 20.5844293\ttotal: 6.8s\tremaining: 34.2ms\n",
            "995:\tlearn: 20.5759156\ttotal: 6.81s\tremaining: 27.4ms\n",
            "996:\tlearn: 20.5712022\ttotal: 6.82s\tremaining: 20.5ms\n",
            "997:\tlearn: 20.5692768\ttotal: 6.82s\tremaining: 13.7ms\n",
            "998:\tlearn: 20.5673626\ttotal: 6.83s\tremaining: 6.84ms\n",
            "999:\tlearn: 20.5633960\ttotal: 6.84s\tremaining: 0us\n",
            "Test\n",
            "MSE & RMSE & R2\n",
            "3675.825862354969 60.62858948016991 0.0776125529423638\n",
            "Train\n",
            "MSE & RMSE & R2\n",
            "422.8532508430765 20.563395897639975 0.6887245542082707\n"
          ]
        }
      ],
      "source": [
        "import catboost\n",
        "\n",
        "model = catboost.CatBoostRegressor()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_test = model.predict(X_test)\n",
        "y_pred_train = model.predict(X_train)\n",
        "draw_metrics(y_pred_test, y_pred_train, y_test, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Catboost справился пока что лучше всех. Давайте попробуем ему скормить сырые данные без преодобработки."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Не совсем вас понял, что такое без преобработки. Если совсем без - она показывает максимально плохой результат, если с предобработкой, то она показывает вполне хороший результат. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "6168394c1d471a8b0e88ebd9b23486d2db9e87763121fc0dd1725bd83c9b54c2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
